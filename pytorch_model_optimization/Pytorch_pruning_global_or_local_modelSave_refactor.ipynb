{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[文章参考来源](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#serializing-a-pruned-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.675683Z",
     "start_time": "2020-05-16T10:33:25.450647Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune  # 用于剪枝的API接口函数\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.681509Z",
     "start_time": "2020-05-16T10:33:25.676838Z"
    }
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)  #输入1通道，输出6通道，kernel_size=3\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10) # 因为是10分类，所以最后一层的神经元个数为10\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # 这里的意思是说，kernel_size=(2, 2) stride=(2, 2), 所以长宽各降一半\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        # 全连接层接受的是二维输入，所以要把[batch_size,C,H,W]转化成二维[batch_size,C*H*W]，.nelement()的作用是统计array里元素个数\n",
    "        # 这里的.view作用相当于进行reshape\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) # 返回logits, 用于计算损失值\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 声明一个LeNet网络的实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.694303Z",
     "start_time": "2020-05-16T10:33:25.682888Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.703421Z",
     "start_time": "2020-05-16T10:33:25.696136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.709931Z",
     "start_time": "2020-05-16T10:33:25.704401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测conv1,其中包含了weight和bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.715502Z",
     "start_time": "2020-05-16T10:33:25.710786Z"
    }
   },
   "outputs": [],
   "source": [
    "module = model.conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先说一下后面会用到的几个概念，model.conv1.weight这里的weight是属性，运行prune操作之后产生的稀疏权重会存储在这里，然后我们需要运行prune.remove()操作，才能让model.conv1.weight和model.conv1.named_parameters()的显示结果变成一样\n",
    "\n",
    "model.conv1.named_buffers()运行操作后，生成的mask会在这里\n",
    "\n",
    "model.conv1.named_parameters()模型参数的存储位置，这里面的值会跟随torch.save存储到本地的.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 观察module或者说是conv1,我们发现了weight和bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.724839Z",
     "start_time": "2020-05-16T10:33:25.716934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.2691, -0.0564,  0.2772],\n",
       "            [-0.1236,  0.2178, -0.0219],\n",
       "            [ 0.1223, -0.3186,  0.1221]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0238, -0.3191,  0.2338],\n",
       "            [ 0.1894,  0.0085, -0.1708],\n",
       "            [ 0.0426,  0.2877, -0.2856]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0800,  0.2898, -0.1054],\n",
       "            [ 0.1463,  0.1642, -0.1048],\n",
       "            [ 0.2176, -0.0798, -0.3266]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3307,  0.1617, -0.0085],\n",
       "            [-0.2245, -0.2782,  0.1207],\n",
       "            [ 0.1837,  0.2102,  0.2704]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2519,  0.1290, -0.1696],\n",
       "            [-0.1173, -0.3266,  0.1383],\n",
       "            [ 0.2638, -0.2733,  0.2444]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1996,  0.1884,  0.1711],\n",
       "            [ 0.1385,  0.1249, -0.0065],\n",
       "            [-0.2338,  0.3312,  0.0967]]]], requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0323,  0.3314, -0.0652,  0.1109, -0.1279,  0.2881],\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用weight属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.730328Z",
     "start_time": "2020-05-16T10:33:25.726975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.2691, -0.0564,  0.2772],\n",
       "          [-0.1236,  0.2178, -0.0219],\n",
       "          [ 0.1223, -0.3186,  0.1221]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0238, -0.3191,  0.2338],\n",
       "          [ 0.1894,  0.0085, -0.1708],\n",
       "          [ 0.0426,  0.2877, -0.2856]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0800,  0.2898, -0.1054],\n",
       "          [ 0.1463,  0.1642, -0.1048],\n",
       "          [ 0.2176, -0.0798, -0.3266]]],\n",
       "\n",
       "\n",
       "        [[[-0.3307,  0.1617, -0.0085],\n",
       "          [-0.2245, -0.2782,  0.1207],\n",
       "          [ 0.1837,  0.2102,  0.2704]]],\n",
       "\n",
       "\n",
       "        [[[-0.2519,  0.1290, -0.1696],\n",
       "          [-0.1173, -0.3266,  0.1383],\n",
       "          [ 0.2638, -0.2733,  0.2444]]],\n",
       "\n",
       "\n",
       "        [[[-0.1996,  0.1884,  0.1711],\n",
       "          [ 0.1385,  0.1249, -0.0065],\n",
       "          [-0.2338,  0.3312,  0.0967]]]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 因为还没使用过conv1,所以这里的buffer为空，调用prune之后你会发现差别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.735547Z",
     "start_time": "2020-05-16T10:33:25.731215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对conv1里的weight进行random_unstructured剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.742778Z",
     "start_time": "2020-05-16T10:33:25.736616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.random_unstructured(module, name='weight', amount=0.3) # 裁剪比例设置为0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 你可以发现这里的weight被重命名为weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.749127Z",
     "start_time": "2020-05-16T10:33:25.743811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0323,  0.3314, -0.0652,  0.1109, -0.1279,  0.2881],\n",
       "         requires_grad=True)),\n",
       " ('weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.2691, -0.0564,  0.2772],\n",
       "            [-0.1236,  0.2178, -0.0219],\n",
       "            [ 0.1223, -0.3186,  0.1221]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0238, -0.3191,  0.2338],\n",
       "            [ 0.1894,  0.0085, -0.1708],\n",
       "            [ 0.0426,  0.2877, -0.2856]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0800,  0.2898, -0.1054],\n",
       "            [ 0.1463,  0.1642, -0.1048],\n",
       "            [ 0.2176, -0.0798, -0.3266]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3307,  0.1617, -0.0085],\n",
       "            [-0.2245, -0.2782,  0.1207],\n",
       "            [ 0.1837,  0.2102,  0.2704]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2519,  0.1290, -0.1696],\n",
       "            [-0.1173, -0.3266,  0.1383],\n",
       "            [ 0.2638, -0.2733,  0.2444]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1996,  0.1884,  0.1711],\n",
       "            [ 0.1385,  0.1249, -0.0065],\n",
       "            [-0.2338,  0.3312,  0.0967]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.conv1.weight这里的weight是属性，运行prune操作之后产生的稀疏权重会存储在这里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.754742Z",
     "start_time": "2020-05-16T10:33:25.750019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2691, -0.0564,  0.2772],\n",
       "          [-0.1236,  0.2178, -0.0219],\n",
       "          [ 0.1223, -0.3186,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -0.3191,  0.2338],\n",
       "          [ 0.0000,  0.0085, -0.0000],\n",
       "          [ 0.0426,  0.2877, -0.2856]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000, -0.1054],\n",
       "          [ 0.1463,  0.1642, -0.1048],\n",
       "          [ 0.2176, -0.0798, -0.3266]]],\n",
       "\n",
       "\n",
       "        [[[-0.3307,  0.1617, -0.0000],\n",
       "          [-0.2245, -0.2782,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.2519,  0.1290, -0.1696],\n",
       "          [-0.1173, -0.0000,  0.1383],\n",
       "          [ 0.0000, -0.2733,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.1996,  0.0000,  0.1711],\n",
       "          [ 0.0000,  0.1249, -0.0065],\n",
       "          [-0.2338,  0.3312,  0.0967]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight   # 你会发现有些地方的值为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.conv1.named_buffers()运行prune操作后，生成的mask会在这里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.761140Z",
     "start_time": "2020-05-16T10:33:25.755731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight_mask',\n",
       "  tensor([[[[1., 1., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 1., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 1., 1.],\n",
       "            [0., 1., 0.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 0.],\n",
       "            [1., 1., 0.],\n",
       "            [0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [1., 0., 1.],\n",
       "            [0., 1., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 1.],\n",
       "            [0., 1., 1.],\n",
       "            [1., 1., 1.]]]]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())  # 因为目前只对weight进行了prune，所以只有weight_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行L1_unstructured剪枝操作,不过这里的剪枝对象是conv1里的bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.766628Z",
     "start_time": "2020-05-16T10:33:25.762575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(module, name='bias', amount=0.3) # 裁剪比例设置为0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们可以发现bias变成了bias_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.772923Z",
     "start_time": "2020-05-16T10:33:25.767526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.2691, -0.0564,  0.2772],\n",
       "            [-0.1236,  0.2178, -0.0219],\n",
       "            [ 0.1223, -0.3186,  0.1221]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0238, -0.3191,  0.2338],\n",
       "            [ 0.1894,  0.0085, -0.1708],\n",
       "            [ 0.0426,  0.2877, -0.2856]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0800,  0.2898, -0.1054],\n",
       "            [ 0.1463,  0.1642, -0.1048],\n",
       "            [ 0.2176, -0.0798, -0.3266]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3307,  0.1617, -0.0085],\n",
       "            [-0.2245, -0.2782,  0.1207],\n",
       "            [ 0.1837,  0.2102,  0.2704]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2519,  0.1290, -0.1696],\n",
       "            [-0.1173, -0.3266,  0.1383],\n",
       "            [ 0.2638, -0.2733,  0.2444]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1996,  0.1884,  0.1711],\n",
       "            [ 0.1385,  0.1249, -0.0065],\n",
       "            [-0.2338,  0.3312,  0.0967]]]], requires_grad=True)),\n",
       " ('bias_orig',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0323,  0.3314, -0.0652,  0.1109, -0.1279,  0.2881],\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生了bias_mask，这样子的话conv1里的weight和bias都进行了剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.779006Z",
     "start_time": "2020-05-16T10:33:25.773741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight_mask',\n",
       "  tensor([[[[1., 1., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 1., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 1., 1.],\n",
       "            [0., 1., 0.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 0.],\n",
       "            [1., 1., 0.],\n",
       "            [0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [1., 0., 1.],\n",
       "            [0., 1., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 1.],\n",
       "            [0., 1., 1.],\n",
       "            [1., 1., 1.]]]])),\n",
       " ('bias_mask', tensor([0., 1., 0., 1., 1., 1.]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行ln_structured剪枝，注意看输出的weight,都是一整个channel为0的，剪枝的话，是可以连续剪枝的，这里是第二次对conv1里的weight进行剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.784102Z",
     "start_time": "2020-05-16T10:33:25.779792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.ln_structured(module, name='weight', amount=0.5, n=2, dim=0)\n",
    "# as we can verify, this will zero out all the connections corresponding to 50%(3 out of 6) of the channels,\n",
    "# while preserving the action of the previous mask\n",
    "# removing the specified amount of (currently unpruned) channels along the specified dim with the lowest L``n``-norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the forward pass to work without modification, the weight attribute needs to exist. The pruning techniques implemented in torch.nn.utils.prune compute the pruned version of the weight(by combining the mask with the original parameter) and store them in the attribute weight. Note, this is no longer a parameter of the module, it is now simply an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.790138Z",
     "start_time": "2020-05-16T10:33:25.784870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2691, -0.0564,  0.2772],\n",
       "          [-0.1236,  0.2178, -0.0219],\n",
       "          [ 0.1223, -0.3186,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -0.3191,  0.2338],\n",
       "          [ 0.0000,  0.0085, -0.0000],\n",
       "          [ 0.0426,  0.2877, -0.2856]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.3307,  0.1617, -0.0000],\n",
       "          [-0.2245, -0.2782,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.798986Z",
     "start_time": "2020-05-16T10:33:25.791153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prune.remove之后，我们发现weight_orig变成了weight, 其实就是把module.weight的值赋值给了weight_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行prune.remove的作用，to make the pruning permanent, remove the re-parametrization in terms of weight_orig and weight_mask, and remove the forward_pre_hook, we can use the remove functionality from torch.nn.utils.prune. Note that this doesn't undo the pruning, as if it never happened. it simply makes it permanent, instead, by reassigning the parameter weight to the model parameters, in its pruned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.804665Z",
     "start_time": "2020-05-16T10:33:25.800249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.remove(module, 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们发现weight_orig变成了weight，而且数值也发生了变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.832613Z",
     "start_time": "2020-05-16T10:33:25.805515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias_orig',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0323,  0.3314, -0.0652,  0.1109, -0.1279,  0.2881],\n",
       "         requires_grad=True)),\n",
       " ('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.2691, -0.0564,  0.2772],\n",
       "            [-0.1236,  0.2178, -0.0219],\n",
       "            [ 0.1223, -0.3186,  0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0000, -0.3191,  0.2338],\n",
       "            [ 0.0000,  0.0085, -0.0000],\n",
       "            [ 0.0426,  0.2877, -0.2856]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0000,  0.0000, -0.0000],\n",
       "            [ 0.0000,  0.0000, -0.0000],\n",
       "            [ 0.0000, -0.0000, -0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3307,  0.1617, -0.0000],\n",
       "            [-0.2245, -0.2782,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0000,  0.0000, -0.0000],\n",
       "            [-0.0000, -0.0000,  0.0000],\n",
       "            [ 0.0000, -0.0000,  0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000, -0.0000],\n",
       "            [-0.0000,  0.0000,  0.0000]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## buffers里的weight_mask不在了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.836762Z",
     "start_time": "2020-05-16T10:33:25.834235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias_mask', tensor([0., 1., 0., 1., 1., 1.]))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prunning multiple parameters in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.842650Z",
     "start_time": "2020-05-16T10:33:25.837711Z"
    }
   },
   "outputs": [],
   "source": [
    "new_model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.880543Z",
     "start_time": "2020-05-16T10:33:25.843548Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, module in new_model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d): # 收集卷积模块\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.2) # 只对weight剪枝，比例为0.2\n",
    "    elif isinstance(module, torch.nn.Linear): # 收集全连接模块\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.4) # 只对weight剪枝，比例为0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.884591Z",
     "start_time": "2020-05-16T10:33:25.881827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(new_model.named_buffers()).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so far, we only looked at what is usually referred to as \"local\" pruning, the practice of pruning tensors in a model one by one, by comparing the statisitcs(weight magnitude, activation, gradient) of each entry exclusively to the other entries in that tensor. however, a common and perhaps more powerful technique is to prune the model all at once, by removing(for example) the lowest 20% of connections across the whole model, instead of removing the lowest 20% of connections in each layer. this is likely to result in different pruning percentages per layer. let's ses how to do that using global_unstructured from torch.nn.utils.prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.890352Z",
     "start_time": "2020-05-16T10:33:25.885530Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设定要剪枝的对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:25.895800Z",
     "start_time": "2020-05-16T10:33:25.891518Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    "    (model.fc3, 'weight')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:26.011682Z",
     "start_time": "2020-05-16T10:33:25.896798Z"
    }
   },
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,  # 接受元组形式\n",
    "    pruning_method=prune.L1Unstructured, # L1非结构化剪枝\n",
    "    amount=0.7 # 裁剪比例设置为0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看每层剪枝比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:26.040417Z",
     "start_time": "2020-05-16T10:33:26.012645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1.weight: 9.26%\n",
      "Sparsity in conv2.weight: 29.40%\n",
      "Sparsity in fc1.weight: 77.20%\n",
      "Sparsity in fc2.weight: 42.57%\n",
      "Sparsity in fc3.weight: 33.45%\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparsity in conv1.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.conv1.weight == 0)) / \n",
    "     float(model.conv1.weight.nelement())))\n",
    "print(\"Sparsity in conv2.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.conv2.weight == 0)) /\n",
    "                                                float(model.conv2.weight.nelement())))\n",
    "print(\"Sparsity in fc1.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc1.weight == 0)) / \n",
    "     float(model.fc1.weight.nelement())))\n",
    "print(\"Sparsity in fc2.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc2.weight == 0)) / \n",
    "     float(model.fc2.weight.nelement())))\n",
    "print(\"Sparsity in fc3.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc3.weight == 0)) /\n",
    "                                              float(model.fc3.weight.nelement())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现每层的剪枝比例都是不相同的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计全局剪枝比例是否和开始设置的值对上了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:26.052739Z",
     "start_time": "2020-05-16T10:33:26.041433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 70.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Global sparsity: {:.2f}%\".format(\n",
    "    100.0 * float(\n",
    "        torch.sum(model.conv1.weight == 0)\n",
    "        + torch.sum(model.conv2.weight == 0)\n",
    "        + torch.sum(model.fc1.weight == 0)\n",
    "        + torch.sum(model.fc2.weight == 0)\n",
    "        + torch.sum(model.fc3.weight == 0)\n",
    "    )\n",
    "    / float(\n",
    "        model.conv1.weight.nelement()\n",
    "        + model.conv2.weight.nelement()\n",
    "        + model.fc1.weight.nelement()\n",
    "        + model.fc2.weight.nelement()\n",
    "        + model.fc3.weight.nelement()\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算0值的个数，结果看来是吻合的，计算结果为12.96%稀疏度，在conv1层的weight上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:26.056473Z",
     "start_time": "2020-05-16T10:33:26.053640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(model.conv1.weight == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:26.062856Z",
     "start_time": "2020-05-16T10:33:26.057511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:26.069125Z",
     "start_time": "2020-05-16T10:33:26.064019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.962962962962962"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 / 54.0 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在保存模型之前，对每个layer运行prune.remove操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:26.083970Z",
     "start_time": "2020-05-16T10:33:26.070490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)) weight\n",
      "Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)) weight\n",
      "Linear(in_features=400, out_features=120, bias=True) weight\n",
      "Linear(in_features=120, out_features=84, bias=True) weight\n",
      "Linear(in_features=84, out_features=10, bias=True) weight\n"
     ]
    }
   ],
   "source": [
    "for module, name in parameters_to_prune:\n",
    "    print(module, name)\n",
    "    prune.remove(module, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们发现weight_orig变成了weight,以及buffers消失了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:26.089020Z",
     "start_time": "2020-05-16T10:33:26.085438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.3147,  0.0444,  0.2716, -0.2634,  0.3191, -0.0852],\n",
       "         requires_grad=True)),\n",
       " ('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-0.1131,  0.2648, -0.1587],\n",
       "            [-0.1643, -0.2121, -0.2425],\n",
       "            [-0.2672,  0.3147, -0.0891]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1982,  0.1679,  0.1454],\n",
       "            [ 0.1489, -0.0921, -0.2199],\n",
       "            [ 0.1776, -0.0715,  0.1888]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2557,  0.0473,  0.0568],\n",
       "            [-0.1301, -0.1119,  0.1975],\n",
       "            [-0.0393, -0.3195,  0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0776,  0.1490,  0.1065],\n",
       "            [-0.0000, -0.0000, -0.2631],\n",
       "            [ 0.0672,  0.3200, -0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0864, -0.2467, -0.1353],\n",
       "            [ 0.2151, -0.2461,  0.1550],\n",
       "            [-0.3023,  0.2745, -0.0648]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3133,  0.1329, -0.0000],\n",
       "            [ 0.0458, -0.2444,  0.2501],\n",
       "            [-0.0965,  0.3150,  0.1124]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:26.094456Z",
     "start_time": "2020-05-16T10:33:26.090035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型以及比较.pth压缩后.zip格式模型的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:26.100924Z",
     "start_time": "2020-05-16T10:33:26.095772Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'sparse_model.pth') #这种方式只保存权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算下剪枝后模型压缩比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:26.110039Z",
     "start_time": "2020-05-16T10:33:26.102102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6232423490488007"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(241.8 - 91.1) / 241.8  # 前者为压缩前，后者为压缩后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T10:33:26.117019Z",
     "start_time": "2020-05-16T10:33:26.110947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.1131,  0.2648, -0.1587],\n",
       "          [-0.1643, -0.2121, -0.2425],\n",
       "          [-0.2672,  0.3147, -0.0891]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1982,  0.1679,  0.1454],\n",
       "          [ 0.1489, -0.0921, -0.2199],\n",
       "          [ 0.1776, -0.0715,  0.1888]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2557,  0.0473,  0.0568],\n",
       "          [-0.1301, -0.1119,  0.1975],\n",
       "          [-0.0393, -0.3195,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0776,  0.1490,  0.1065],\n",
       "          [-0.0000, -0.0000, -0.2631],\n",
       "          [ 0.0672,  0.3200, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0864, -0.2467, -0.1353],\n",
       "          [ 0.2151, -0.2461,  0.1550],\n",
       "          [-0.3023,  0.2745, -0.0648]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3133,  0.1329, -0.0000],\n",
       "          [ 0.0458, -0.2444,  0.2501],\n",
       "          [-0.0965,  0.3150,  0.1124]]]], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
