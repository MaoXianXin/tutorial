{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存.h5模型，这里使用的是MobileNetV2，而且是在ImageNet上预训练过的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T13:12:24.396413Z",
     "start_time": "2020-05-13T13:12:17.120208Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 as Net\n",
    "\n",
    "model = Net(weights='imagenet')\n",
    "\n",
    "os.makedirs('./model', exist_ok=True)\n",
    "\n",
    "# Save the h5 file to path specified.\n",
    "model.save(\"./model/mobilenetv2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将.h5文件转化成frozen graph，并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T13:12:27.098710Z",
     "start_time": "2020-05-13T13:12:24.397594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "['input_1'] ['Logits/Softmax']\n",
      "WARNING:tensorflow:From <ipython-input-2-4f73380c46f7>:14: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.remove_training_nodes`\n",
      "WARNING:tensorflow:From <ipython-input-2-4f73380c46f7>:15: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/mao/anaconda3/envs/tf1.14/lib/python3.7/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 262 variables.\n",
      "INFO:tensorflow:Converted 262 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "\n",
    "# Clear any previous session.\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "save_pb_dir = './model'\n",
    "model_fname = './model/mobilenetv2.h5'\n",
    "def freeze_graph(graph, session, output, save_pb_dir='.', save_pb_name='fp32_frozen_graph.pb', save_pb_as_text=False):\n",
    "    with graph.as_default():\n",
    "        graphdef_inf = tf.graph_util.remove_training_nodes(graph.as_graph_def())\n",
    "        graphdef_frozen = tf.graph_util.convert_variables_to_constants(session, graphdef_inf, output)\n",
    "        graph_io.write_graph(graphdef_frozen, save_pb_dir, save_pb_name, as_text=save_pb_as_text)\n",
    "        return graphdef_frozen\n",
    "\n",
    "# This line must be executed before loading Keras model.\n",
    "tf.keras.backend.set_learning_phase(0) \n",
    "\n",
    "model = load_model(model_fname)\n",
    "\n",
    "session = tf.keras.backend.get_session()\n",
    "\n",
    "input_names = [t.op.name for t in model.inputs]\n",
    "output_names = [t.op.name for t in model.outputs]\n",
    "\n",
    "# Prints input and output nodes names, take notes of them.\n",
    "print(input_names, output_names)\n",
    "\n",
    "fp32_frozen_graph = freeze_graph(session.graph, session, [out.op.name for out in model.outputs], save_pb_dir=save_pb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将frozen graph转化成FP32的.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T13:12:39.822100Z",
     "start_time": "2020-05-13T13:12:38.791634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13973776"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "graph_def_file = \"./model/fp32_frozen_graph.pb\"\n",
    "input_arrays = [\"input_1\"]\n",
    "output_arrays = ['Logits/Softmax']\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_frozen_graph(\n",
    "  graph_def_file, input_arrays, output_arrays)\n",
    "tflite_model = converter.convert()\n",
    "open(\"./model/fp32_frozen_graph.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取一张图片用于calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "# Optional image to test model prediction.\n",
    "img_path = './elephant.jpg'\n",
    "\n",
    "image_size = [224, 224, 3]\n",
    "img = image.load_img(img_path, target_size=image_size[:2])\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转化成.tflite过程中引入integer quantization，此处是FP32->INT8的转化，所以要引入calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3) (1, 224, 224, 3)\n",
      "(1, 224, 224, 3) (1, 224, 224, 3)\n",
      "Calibration data shape:  (2, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "num_calibration_batches = 2\n",
    "BATCH_SIZE = 1\n",
    "batched_input = np.zeros((BATCH_SIZE * num_calibration_batches, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Session(graph=tf.Graph(), config=config) as sess:\n",
    "    # prepare dataset iterator\n",
    "    next_element = tf.convert_to_tensor(x)\n",
    "    for i in range(num_calibration_batches):\n",
    "        print(batched_input[i*BATCH_SIZE:(i+1)*BATCH_SIZE, :].shape, sess.run(next_element).shape)\n",
    "        batched_input[i*BATCH_SIZE:(i+1)*BATCH_SIZE, :] = sess.run(next_element)\n",
    "\n",
    "#batched_input = tf.constant(batched_input)\n",
    "print('Calibration data shape: ', batched_input.shape)\n",
    "\n",
    "def calibration_input_fn_gen():\n",
    "    for i in range(num_calibration_batches):\n",
    "        yield [batched_input[i*BATCH_SIZE:(i+1)*BATCH_SIZE, :]]\n",
    "        \n",
    "calibration_input_fn = calibration_input_fn_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3979896"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "graph_def_file = \"./model/fp32_frozen_graph.pb\"\n",
    "input_arrays = [\"input_1\"]\n",
    "output_arrays = ['Logits/Softmax']\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_frozen_graph(\n",
    "  graph_def_file, input_arrays, output_arrays)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = calibration_input_fn_gen\n",
    "tflite_model = converter.convert()\n",
    "open(\"./model/int8_frozen_graph.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 封装好的Inference函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfLiteInference(input_details, interpreter, output_details, x):\n",
    "    interpreter.set_tensor(input_details[0]['index'], x)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试FP32的.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"./model/fp32_frozen_graph.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Optional image to test model prediction.\n",
    "img_path = './elephant.jpg'\n",
    "\n",
    "image_size = [224, 224, 3]\n",
    "img = image.load_img(img_path, target_size=image_size[:2])\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02504458', 'African_elephant', 0.40645647), ('n02504013', 'Indian_elephant', 0.26055372), ('n01871265', 'tusker', 0.14443965)]\n",
      "average(sec):0.02,fps:64.40\n"
     ]
    }
   ],
   "source": [
    "# test FP32 CPU\n",
    "import time\n",
    "times = []\n",
    "\n",
    "output_data = tfLiteInference(input_details, interpreter, output_details, x)\n",
    "\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(output_data, top=3)[0])\n",
    "\n",
    "for i in range(2000):\n",
    "    start_time = time.time()\n",
    "    output_data = tfLiteInference(input_details, interpreter, output_details, x)\n",
    "    delta = (time.time() - start_time)\n",
    "    times.append(delta)\n",
    "mean_delta = np.array(times).mean()\n",
    "fps = 1 / mean_delta\n",
    "print('average(sec):{:.2f},fps:{:.2f}'.format(mean_delta, fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到它的FPS是64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试INT8的.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"./model/int8_frozen_graph.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Optional image to test model prediction.\n",
    "img_path = './elephant.jpg'\n",
    "\n",
    "image_size = [224, 224, 3]\n",
    "img = image.load_img(img_path, target_size=image_size[:2])\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02504458', 'African_elephant', 0.45703125), ('n02504013', 'Indian_elephant', 0.18359375), ('n01871265', 'tusker', 0.13671875)]\n",
      "average(sec):0.91,fps:1.10\n"
     ]
    }
   ],
   "source": [
    "# test INT8 CPU\n",
    "import time\n",
    "times = []\n",
    "\n",
    "output_data = tfLiteInference(input_details, interpreter, output_details, x)\n",
    "\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(output_data, top=3)[0])\n",
    "\n",
    "for i in range(20):\n",
    "    start_time = time.time()\n",
    "    output_data = tfLiteInference(input_details, interpreter, output_details, x)\n",
    "    delta = (time.time() - start_time)\n",
    "    times.append(delta)\n",
    "mean_delta = np.array(times).mean()\n",
    "fps = 1 / mean_delta\n",
    "print('average(sec):{:.2f},fps:{:.2f}'.format(mean_delta, fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到它的FPS是1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对FP32和INT8的FPS问题，还需要深入挖掘一下"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
