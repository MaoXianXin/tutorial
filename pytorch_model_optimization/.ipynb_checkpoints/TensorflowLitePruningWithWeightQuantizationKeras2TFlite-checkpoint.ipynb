{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:00.621911Z",
     "start_time": "2020-05-21T08:25:59.761902Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow_model_optimization # 引入tensorflow自带的优化接口\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity  # 该接口只用于剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:00.648031Z",
     "start_time": "2020-05-21T08:26:00.623097Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:00.669995Z",
     "start_time": "2020-05-21T08:26:00.649013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:00.677190Z",
     "start_time": "2020-05-21T08:26:00.674762Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:01.154249Z",
     "start_time": "2020-05-21T08:26:00.678006Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() # 选用的是cifar10数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把数据集的INT8转换成Float32类型，对标签进行独热编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:01.343991Z",
     "start_time": "2020-05-21T08:26:01.155135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255  # 缩放到[0,1]\n",
    "x_test /= 255\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "num_classes = 10  # cifar10属于10分类问题\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes = 10) # 对标签进行独热编码\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 展示编码后的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:01.351089Z",
     "start_time": "2020-05-21T08:26:01.345343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建VGG16模型，用于cifar10分类，代码参考自keras github的VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型的一些参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:01.358865Z",
     "start_time": "2020-05-21T08:26:01.352125Z"
    }
   },
   "outputs": [],
   "source": [
    "backend = tf.keras.backend\n",
    "layers = tf.keras.layers\n",
    "models = tf.keras.models\n",
    "keras_utils = tf.keras.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:01.364774Z",
     "start_time": "2020-05-21T08:26:01.359832Z"
    }
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
    "                       'releases/download/v0.1/'\n",
    "                       'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')  # 此处的预训练模型不带全连接层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建VGG16模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:01.377548Z",
     "start_time": "2020-05-21T08:26:01.365719Z"
    }
   },
   "outputs": [],
   "source": [
    "def VGG16(include_top=False,\n",
    "         weights='imagenet',\n",
    "         input_tensor=None,\n",
    "         input_shape=(32, 32, 3),\n",
    "         pooling='avg',\n",
    "         classes=10,\n",
    "         **kwargs):\n",
    "    img_input = layers.Input(shape=input_shape)  # 输入节点\n",
    "    \n",
    "    # Block 1\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(img_input)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    if pooling == 'avg':\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(128, activation='relu', name='fc1')(x)\n",
    "        x = layers.Dense(classes, activation='softmax', name='predictions')(x) # 此处是10分类，而不是ImageNet的1000分类\n",
    "    \n",
    "    inputs = img_input  # 输入节点, x是输出节点\n",
    "    model = models.Model(inputs, x , name='vgg16')  # 生成一个Model, 需要指定输入和输出\n",
    "    \n",
    "    weights_path = keras_utils.get_file(\n",
    "        'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',  # 此处加载的是不存在全连接层的预训练模型\n",
    "        WEIGHTS_PATH_NO_TOP,\n",
    "        cache_subdir='models',\n",
    "        file_hash='6d6bbae143d832006294945121d1f1fc')\n",
    "    model.load_weights(weights_path, by_name=True)  # 加载在ImageNet上预训练过的模型，注意by_name参数很有用\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例化一个vgg16对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:01.960049Z",
     "start_time": "2020-05-21T08:26:01.378636Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg16 = VGG16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看模型的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:01.967093Z",
     "start_time": "2020-05-21T08:26:01.960862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 14,781,642\n",
      "Trainable params: 14,781,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对模型进行剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置pruning参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:01.974321Z",
     "start_time": "2020-05-21T08:26:01.968034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End step: 3910\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "num_train_samples = x_train.shape[0]\n",
    "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
    "print('End step: ' + str(end_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:01.980507Z",
     "start_time": "2020-05-21T08:26:01.975108Z"
    }
   },
   "outputs": [],
   "source": [
    "pruning_params = {\n",
    "    'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.5,  # 起始稀疏度\n",
    "                                                final_sparsity=0.9,  # 最终稀疏度\n",
    "                                                begin_step=2000,  # 从哪一个step开始剪枝\n",
    "                                                end_step=end_step,  # 剪枝结束的step\n",
    "                                                frequency=100)  # 每100个step进行剪枝一次\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得到剪枝后的vgg16模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:03.545484Z",
     "start_time": "2020-05-21T08:26:01.981352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mao/.virtualenvs/tf2.0/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:199: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "vgg16_pruned = sparsity.prune_low_magnitude(vgg16, **pruning_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看剪枝后的模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:03.554190Z",
     "start_time": "2020-05-21T08:26:03.546442Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block1_c (None, 32, 32, 64)        3522      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block1_c (None, 32, 32, 64)        73794     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block1_p (None, 16, 16, 64)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block2_c (None, 16, 16, 128)       147586    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block2_c (None, 16, 16, 128)       295042    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block2_p (None, 8, 8, 128)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block3_c (None, 8, 8, 256)         590082    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block3_c (None, 8, 8, 256)         1179906   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block3_c (None, 8, 8, 256)         1179906   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block3_p (None, 4, 4, 256)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block4_c (None, 4, 4, 512)         2359810   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block4_c (None, 4, 4, 512)         4719106   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block4_c (None, 4, 4, 512)         4719106   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block4_p (None, 2, 2, 512)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block5_c (None, 2, 2, 512)         4719106   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block5_c (None, 2, 2, 512)         4719106   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block5_c (None, 2, 2, 512)         4719106   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block5_p (None, 1, 1, 512)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_global_a (None, 512)               1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_fc1 (Pru (None, 128)               131202    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_predicti (None, 10)                2572      \n",
      "=================================================================\n",
      "Total params: 29,558,958\n",
      "Trainable params: 14,781,642\n",
      "Non-trainable params: 14,777,316\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_pruned.summary()  # 多了一层pruning wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置Logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:03.567754Z",
     "start_time": "2020-05-21T08:26:03.555164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing training logs to /tmp/tmp6j8xfho7\n"
     ]
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "print('writing training logs to ' + logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:03.581638Z",
     "start_time": "2020-05-21T08:26:03.568646Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg16_pruned.compile(\n",
    "    loss = tf.keras.losses.categorical_crossentropy, # 分类模型一般用这个损失函数\n",
    "    optimizer = 'adam',  # 采用的优化器\n",
    "    metrics = ['accuracy'] # 此处只评估准确率\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:26:03.584300Z",
     "start_time": "2020-05-21T08:26:03.582555Z"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    sparsity.UpdatePruningStep(),\n",
    "    sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:29:05.229730Z",
     "start_time": "2020-05-21T08:26:03.585017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 19s 47ms/step - loss: 1.9519 - accuracy: 0.2273 - val_loss: 1.6920 - val_accuracy: 0.3350\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 1.3856 - accuracy: 0.4677 - val_loss: 1.1688 - val_accuracy: 0.5741\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 1.0401 - accuracy: 0.6245 - val_loss: 0.9333 - val_accuracy: 0.6649\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8149 - accuracy: 0.7130 - val_loss: 0.7993 - val_accuracy: 0.7276\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 0.6743 - accuracy: 0.7700 - val_loss: 0.8281 - val_accuracy: 0.7263\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.5693 - accuracy: 0.8073 - val_loss: 0.6803 - val_accuracy: 0.7734\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 0.4997 - accuracy: 0.8337 - val_loss: 0.6651 - val_accuracy: 0.7845\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 0.5288 - accuracy: 0.8234 - val_loss: 0.7017 - val_accuracy: 0.7745\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 17s 45ms/step - loss: 0.4149 - accuracy: 0.8617 - val_loss: 0.6185 - val_accuracy: 0.8042\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 18s 45ms/step - loss: 0.3091 - accuracy: 0.8963 - val_loss: 0.6504 - val_accuracy: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6d44655358>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_pruned.fit(x_train, y_train,\n",
    "                batch_size = 128,\n",
    "                epochs = epochs,\n",
    "                verbose=1,\n",
    "                callbacks = callbacks,\n",
    "                validation_data = (x_test, y_test)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估模型损失值和正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:29:07.887662Z",
     "start_time": "2020-05-21T08:29:05.234422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.6503599882125854\n",
      "Test accuracy:  0.8100000023841858\n"
     ]
    }
   ],
   "source": [
    "score = vgg16_pruned.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对模型去除pruning wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:29:07.940524Z",
     "start_time": "2020-05-21T08:29:07.889279Z"
    }
   },
   "outputs": [],
   "source": [
    "final_model = sparsity.strip_pruning(vgg16_pruned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:29:08.039562Z",
     "start_time": "2020-05-21T08:29:07.941480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pruned model to:  /tmp/tmpeex9bw3p.h5\n"
     ]
    }
   ],
   "source": [
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving pruned model to: ', pruned_keras_file)\n",
    "tf.keras.models.save_model(final_model, pruned_keras_file, include_optimizer=False)  # 这里只保存模型权重，所以optimizer=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对剪枝模型进行压缩，对未剪枝模型进行压缩，对比两者大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:29:10.098228Z",
     "start_time": "2020-05-21T08:29:08.040445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the pruned model before compression: 56.45 Mb\n",
      "Size of the pruned model after compression: 10.83 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip3 = tempfile.mkstemp('.zip')\n",
    "with zipfile.ZipFile(zip3, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(pruned_keras_file)\n",
    "print(\"Size of the pruned model before compression: %.2f Mb\" \n",
    "      % (os.path.getsize(pruned_keras_file) / float(2**20)))\n",
    "print(\"Size of the pruned model after compression: %.2f Mb\" \n",
    "      % (os.path.getsize(zip3) / float(2**20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转化成FP32的.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:29:49.856411Z",
     "start_time": "2020-05-21T08:29:49.836191Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'call'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-fcbbef8ef0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtflite_model_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./sparse_cifar10.tflite'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpruned_keras_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 获得converter对象\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 进行转换\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf2.0/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_keras_model\u001b[0;34m(cls, model)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;31m# to None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;31m# Once we have better support for dynamic shapes, we can remove this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_def_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m       \u001b[0;31m# Pass `keep_original_batch_size=True` will ensure that we get an input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m       \u001b[0;31m# signature including the batch dimension specified by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'call'"
     ]
    }
   ],
   "source": [
    "tflite_model_file = './sparse_cifar10.tflite'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model) # 获得converter对象\n",
    "tflite_model = converter.convert()  # 进行转换\n",
    "with open(tflite_model_file, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 封装TFLite模型准确率验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:29:10.204908Z",
     "start_time": "2020-05-21T08:25:59.811Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_model(interpreter, x_test, y_test):\n",
    "    total_seen = 0\n",
    "    num_correct = 0\n",
    "    \n",
    "    for img, label in zip(x_test, y_test):\n",
    "        inp = img.reshape((1, 32, 32, 3))\n",
    "        total_seen += 1\n",
    "        interpreter.set_tensor(input_index, inp)  # 获得输入\n",
    "        interpreter.invoke()  # 执行推断\n",
    "        predictions = interpreter.get_tensor(output_index) # 获取输出\n",
    "        \n",
    "        if np.argmax(predictions) == np.argmax(label):\n",
    "            num_correct += 1\n",
    "        \n",
    "        if total_seen % 1000 == 0:\n",
    "            print('Accuracy after %i images: %f' % (total_seen, float(num_correct) / float(total_seen)))\n",
    "    \n",
    "    return float(num_correct) / float(total_seen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转化成FP32的.tflite，我们发现模型没什么变化，只是存储格式发生了变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:29:10.205366Z",
     "start_time": "2020-05-21T08:25:59.813Z"
    }
   },
   "outputs": [],
   "source": [
    "_, zip_tflite = tempfile.mkstemp('.zip')\n",
    "with zipfile.ZipFile(zip_tflite, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(tflite_model_file)\n",
    "print(\"Size of the tflite model before compression: %.2f Mb\" \n",
    "      % (os.path.getsize(tflite_model_file) / float(2**20)))\n",
    "print(\"Size of the tflite model after compression: %.2f Mb\" \n",
    "      % (os.path.getsize(zip_tflite) / float(2**20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证FP32的.tflite模型准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:29:10.205808Z",
     "start_time": "2020-05-21T08:25:59.816Z"
    }
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))  # 获取interpreter对象\n",
    "interpreter.allocate_tensors() # 为tensor分配内存\n",
    "input_index = interpreter.get_input_details()[0][\"index\"] # 获取输入\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]  # 获取输出\n",
    "\n",
    "eval_model(interpreter, x_test, y_test)  # 执行评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转化过程中引入weight_quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:29:10.206203Z",
     "start_time": "2020-05-21T08:25:59.818Z"
    }
   },
   "outputs": [],
   "source": [
    "tflite_quant_model_file = './sparse_cifar10_quant.tflite'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(pruned_keras_file) # 获得converter对象\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_quant_model = converter.convert() # 进行转换\n",
    "with open(tflite_quant_model_file, 'wb') as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对比weight_quantization前后模型体积变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:29:10.206588Z",
     "start_time": "2020-05-21T08:25:59.821Z"
    }
   },
   "outputs": [],
   "source": [
    "_, zip_tflite = tempfile.mkstemp('.zip')\n",
    "with zipfile.ZipFile(zip_tflite, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(tflite_quant_model_file)\n",
    "print(\"Size of the tflite model before compression: %.2f Mb\" \n",
    "      % (os.path.getsize(tflite_quant_model_file) / float(2**20)))\n",
    "print(\"Size of the tflite model after compression: %.2f Mb\" \n",
    "      % (os.path.getsize(zip_tflite) / float(2**20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证tflite模型准确率,查看weight quantization后，下降了多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T08:29:10.206976Z",
     "start_time": "2020-05-21T08:25:59.823Z"
    }
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_quant_model_file)) # 获得interpreter对象\n",
    "interpreter.allocate_tensors() # 为tensor分配内存\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]  # 获取输入\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]  #  获取输出\n",
    "\n",
    "eval_model(interpreter, x_test, y_test)  # 执行评估函数"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
