{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存.h5模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mao/.virtualenvs/tf_quantization/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 as Net\n",
    "\n",
    "model = Net(weights='imagenet')\n",
    "\n",
    "os.makedirs('./model', exist_ok=True)\n",
    "\n",
    "# Save the h5 file to path specified.\n",
    "model.save(\"./model/mobilenetv2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把.h5转化成frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mao/.virtualenvs/tf_quantization/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mao/.virtualenvs/tf_quantization/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mao/.virtualenvs/tf_quantization/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "['input_1'] ['Logits/Softmax']\n",
      "WARNING:tensorflow:From <ipython-input-2-4f73380c46f7>:14: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.remove_training_nodes`\n",
      "WARNING:tensorflow:From <ipython-input-2-4f73380c46f7>:15: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/mao/.virtualenvs/tf_quantization/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 262 variables.\n",
      "INFO:tensorflow:Converted 262 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "\n",
    "# Clear any previous session.\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "save_pb_dir = './model'\n",
    "model_fname = './model/mobilenetv2.h5'\n",
    "def freeze_graph(graph, session, output, save_pb_dir='.', save_pb_name='fp32_frozen_graph.pb', save_pb_as_text=False):\n",
    "    with graph.as_default():\n",
    "        graphdef_inf = tf.graph_util.remove_training_nodes(graph.as_graph_def())\n",
    "        graphdef_frozen = tf.graph_util.convert_variables_to_constants(session, graphdef_inf, output)\n",
    "        graph_io.write_graph(graphdef_frozen, save_pb_dir, save_pb_name, as_text=save_pb_as_text)\n",
    "        return graphdef_frozen\n",
    "\n",
    "# This line must be executed before loading Keras model.\n",
    "tf.keras.backend.set_learning_phase(0) \n",
    "\n",
    "model = load_model(model_fname)\n",
    "\n",
    "session = tf.keras.backend.get_session()\n",
    "\n",
    "input_names = [t.op.name for t in model.inputs]\n",
    "output_names = [t.op.name for t in model.outputs]\n",
    "\n",
    "# Prints input and output nodes names, take notes of them.\n",
    "print(input_names, output_names)\n",
    "\n",
    "fp32_frozen_graph = freeze_graph(session.graph, session, [out.op.name for out in model.outputs], save_pb_dir=save_pb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把frozen graph转化成tensorRT的FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (5, 1, 5)\n",
      "INFO:tensorflow:Loaded TensorRT version: (5, 1, 5)\n",
      "INFO:tensorflow:Running against TensorRT version 5.1.5\n"
     ]
    }
   ],
   "source": [
    "#Now we create the TFTRT FP32 engine\n",
    "BATCH_SIZE = 8\n",
    "converter = trt.TrtGraphConverter(input_graph_def=fp32_frozen_graph,\n",
    "                                  max_batch_size=BATCH_SIZE,\n",
    "                                  precision_mode=trt.TrtPrecisionMode.FP32,\n",
    "                                  nodes_blacklist=['Logits/Softmax'])\n",
    "trt_fp32_graph = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model/trt_fp32_graph.pb'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.framework import graph_io\n",
    "graph_io.write_graph(trt_fp32_graph, \"./model/\",\n",
    "                     \"trt_fp32_graph.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试FP32的frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-30cd100cbc5d>:9: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "image_size: [224, 224, 3]\n",
      "input_tensor_name: input_1:0\n",
      "output_tensor_name: Logits/Softmax:0\n"
     ]
    }
   ],
   "source": [
    "output_names = ['Logits/Softmax']\n",
    "input_names = ['input_1']\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_frozen_graph(graph_file):\n",
    "    \"\"\"Read Frozen Graph file from disk.\"\"\"\n",
    "    with tf.gfile.FastGFile(graph_file, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    return graph_def\n",
    "\n",
    "\n",
    "trt_graph = get_frozen_graph('./model/fp32_frozen_graph.pb')\n",
    "\n",
    "# Create session and load graph\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "tf_sess = tf.Session(config=tf_config)\n",
    "tf.import_graph_def(trt_graph, name='')\n",
    "\n",
    "\n",
    "# Get graph input size\n",
    "for node in trt_graph.node:\n",
    "    if 'input_' in node.name:\n",
    "        size = node.attr['shape'].shape\n",
    "        image_size = [size.dim[i].size for i in range(1, 4)]\n",
    "        break\n",
    "print(\"image_size: {}\".format(image_size))\n",
    "\n",
    "\n",
    "# input and output tensor names.\n",
    "input_tensor_name = input_names[0] + \":0\"\n",
    "output_tensor_name = output_names[0] + \":0\"\n",
    "\n",
    "print(\"input_tensor_name: {}\\noutput_tensor_name: {}\".format(\n",
    "    input_tensor_name, output_tensor_name))\n",
    "\n",
    "output_tensor = tf_sess.graph.get_tensor_by_name(output_tensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02504458', 'African_elephant', 0.5241101), ('n01871265', 'tusker', 0.17158917), ('n02504013', 'Indian_elephant', 0.15654118)]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "# Optional image to test model prediction.\n",
    "img_path = './data/elephant.jpg'\n",
    "\n",
    "img = image.load_img(img_path, target_size=image_size[:2])\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "feed_dict = {\n",
    "    input_tensor_name: x\n",
    "}\n",
    "preds = tf_sess.run(output_tensor, feed_dict)\n",
    "\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average(sec):0.00,fps:272.44\n"
     ]
    }
   ],
   "source": [
    "# test FP32\n",
    "import time\n",
    "times = []\n",
    "\n",
    "one_prediction = tf_sess.run(output_tensor, feed_dict)\n",
    "\n",
    "for i in range(2000):\n",
    "    start_time = time.time()\n",
    "    one_prediction = tf_sess.run(output_tensor, feed_dict)\n",
    "    delta = (time.time() - start_time)\n",
    "    times.append(delta)\n",
    "mean_delta = np.array(times).mean()\n",
    "fps = 1 / mean_delta\n",
    "print('average(sec):{:.2f},fps:{:.2f}'.format(mean_delta, fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试FP32的tensorRT frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-ff9abf669902>:9: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "image_size: [224, 224, 3]\n",
      "input_tensor_name: input_1:0\n",
      "output_tensor_name: Logits/Softmax:0\n"
     ]
    }
   ],
   "source": [
    "output_names = ['Logits/Softmax']\n",
    "input_names = ['input_1']\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_frozen_graph(graph_file):\n",
    "    \"\"\"Read Frozen Graph file from disk.\"\"\"\n",
    "    with tf.gfile.FastGFile(graph_file, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    return graph_def\n",
    "\n",
    "\n",
    "trt_graph = get_frozen_graph('./model/trt_fp32_graph.pb')\n",
    "\n",
    "# Create session and load graph\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "tf_sess = tf.Session(config=tf_config)\n",
    "tf.import_graph_def(trt_graph, name='')\n",
    "\n",
    "\n",
    "# Get graph input size\n",
    "for node in trt_graph.node:\n",
    "    if 'input_' in node.name:\n",
    "        size = node.attr['shape'].shape\n",
    "        image_size = [size.dim[i].size for i in range(1, 4)]\n",
    "        break\n",
    "print(\"image_size: {}\".format(image_size))\n",
    "\n",
    "\n",
    "# input and output tensor names.\n",
    "input_tensor_name = input_names[0] + \":0\"\n",
    "output_tensor_name = output_names[0] + \":0\"\n",
    "\n",
    "print(\"input_tensor_name: {}\\noutput_tensor_name: {}\".format(\n",
    "    input_tensor_name, output_tensor_name))\n",
    "\n",
    "output_tensor = tf_sess.graph.get_tensor_by_name(output_tensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02504458', 'African_elephant', 0.5241092), ('n01871265', 'tusker', 0.17159012), ('n02504013', 'Indian_elephant', 0.15654182)]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "# Optional image to test model prediction.\n",
    "img_path = './data/elephant.jpg'\n",
    "\n",
    "img = image.load_img(img_path, target_size=image_size[:2])\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "feed_dict = {\n",
    "    input_tensor_name: x\n",
    "}\n",
    "preds = tf_sess.run(output_tensor, feed_dict)\n",
    "\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average(sec):0.00,fps:387.24\n"
     ]
    }
   ],
   "source": [
    "# test FP32 TF-TRT\n",
    "import time\n",
    "times = []\n",
    "\n",
    "one_prediction = tf_sess.run(output_tensor, feed_dict)\n",
    "\n",
    "for i in range(2000):\n",
    "    start_time = time.time()\n",
    "    one_prediction = tf_sess.run(output_tensor, feed_dict)\n",
    "    delta = (time.time() - start_time)\n",
    "    times.append(delta)\n",
    "mean_delta = np.array(times).mean()\n",
    "fps = 1 / mean_delta\n",
    "print('average(sec):{:.2f},fps:{:.2f}'.format(mean_delta, fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(one_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
