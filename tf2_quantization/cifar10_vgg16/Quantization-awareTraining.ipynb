{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:07:59.550996Z",
     "start_time": "2020-06-01T07:07:58.530897Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras  # 在TF2.0版本中,已经是自带Keras了,所以不需要额外安装\n",
    "import tensorflow_model_optimization as tfmot  # 导入TF2.0的模型优化函数库,降低模型优化难度,相当于调用借口解决问题\n",
    "import zipfile\n",
    "import tempfile\n",
    "import tensorflow_datasets as tfds # 这个是之前说过的Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如果出现显存不够的错误,把这个代码加上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以展示下不加这个出现错误的情形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:07:59.596137Z",
     "start_time": "2020-06-01T07:07:59.552152Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加入下面这个代码片段主要是因为TF2.0对RTX20系列显卡支持不是很好,容易爆显存,所以设置成用多少占多少显存,而不是一次性全占了(默认)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一些参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:07:59.609956Z",
     "start_time": "2020-06-01T07:07:59.597038Z"
    }
   },
   "outputs": [],
   "source": [
    "layers = tf.keras.layers\n",
    "models = tf.keras.models\n",
    "keras_utils = tf.keras.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:07:59.615974Z",
     "start_time": "2020-06-01T07:07:59.610939Z"
    }
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
    "                       'releases/download/v0.1/'\n",
    "                       'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')  # 此处的预训练模型不带全连接层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16模型改写用于Cifar10分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:07:59.625851Z",
     "start_time": "2020-06-01T07:07:59.616764Z"
    }
   },
   "outputs": [],
   "source": [
    "# 关于这里把官方VGG16函数拿了出来,原因是这样的,我们知道Keras主要有Sequential model和Functional model两种构建模型方式,\n",
    "# 而在进行迁移学习的时候，我们经常是加载预训练的模型(设置include_top=False),此时我们很常见的做法是add layer到模型上,\n",
    "# 这样会形成模型嵌套,这个在使用global_pruning的时候会出错,所以我把VGG16函数拿了出来,手动改了下\n",
    "def VGG16(include_top=False,\n",
    "         weights='imagenet',\n",
    "         input_shape=(32, 32, 3),\n",
    "         pooling='avg',\n",
    "         classes=10,\n",
    "         **kwargs):\n",
    "    img_input = layers.Input(shape=input_shape)  # 输入节点\n",
    "    \n",
    "    # Block 1\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(img_input)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    if pooling == 'avg':\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(128, activation='relu', name='fc1')(x)\n",
    "        x = layers.Dense(classes, activation='softmax', name='predictions')(x) # 此处是10分类，而不是ImageNet的1000分类\n",
    "    \n",
    "    inputs = img_input  # inputs是输入节点, x是输出节点\n",
    "    model = models.Model(inputs, x , name='vgg16')  # 生成一个Model, 需要指定输入和输出\n",
    "    \n",
    "    weights_path = keras_utils.get_file(\n",
    "        'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',  # 此处加载的是不存在全连接层的预训练模型\n",
    "        WEIGHTS_PATH_NO_TOP,\n",
    "        cache_subdir='models',\n",
    "        file_hash='6d6bbae143d832006294945121d1f1fc')\n",
    "    model.load_weights(weights_path, by_name=True)  \n",
    "    # 加载在ImageNet上预训练过的模型，注意by_name参数很有用，把layer和layer name对应上了\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 声明一个VGG16模型实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:08:00.233273Z",
     "start_time": "2020-06-01T07:07:59.626741Z"
    }
   },
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "model.load_weights('./baseline_finetune.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这个函数可以用于查看网络结构和参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:08:00.240927Z",
     "start_time": "2020-06-01T07:08:00.234692Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 14,781,642\n",
      "Trainable params: 14,781,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对特征提取层进行冻结,加快模型训练速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以展示下不加的情形，更直观的说明为什么需要训练更长时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:08:00.251408Z",
     "start_time": "2020-06-01T07:08:00.242328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "length = len(model.layers)  # 查看模型有多少层Layer\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:08:00.259983Z",
     "start_time": "2020-06-01T07:08:00.252286Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in range(length):\n",
    "    print(model.layers[i].trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:08:00.265643Z",
     "start_time": "2020-06-01T07:08:00.260906Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n",
    "    return image, label\n",
    "\n",
    "def augment(image, label):\n",
    "    image, label = convert(image, label)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 38, 38) # Add 6 pixels of padding\n",
    "    image = tf.image.random_crop(image, size=[32, 32, 3]) # Random crop back to 32x32\n",
    "    image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:08:00.495825Z",
     "start_time": "2020-06-01T07:08:00.266559Z"
    }
   },
   "outputs": [],
   "source": [
    "# 此处使用tfds的方式构建data pipeline\n",
    "(raw_test, raw_train), metadata = tfds.load(\n",
    "    'cifar10',\n",
    "    split=['test', 'train'],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "IMG_SIZE = 32 # All images will be resized to 32X32\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "SHUFFLE_BUFFER_SIZE = 50000\n",
    "\n",
    "# 可以体验下这里是否加prefetch(tf.data.experimental.AUTOTUNE)和cache()的区别，对训练速度，以及CPU负载有影响\n",
    "train_batches = raw_train.shuffle(SHUFFLE_BUFFER_SIZE, reshuffle_each_iteration=True).map(augment).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_batches = raw_test.map(convert).batch(BATCH_SIZE)\n",
    "\n",
    "# compile模型并训练\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline的test acc和推断速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:08:03.649450Z",
     "start_time": "2020-06-01T07:08:00.496661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 22ms/step - loss: 1.6255 - accuracy: 0.8348\n",
      "Baseline test accuracy:  0.8348000049591064\n",
      "Saved baseline model to:  ./test.h5\n"
     ]
    }
   ],
   "source": [
    "# 此处我们可以看到Baseline的test acc和inference速度为6ms/step\n",
    "_, baseline_model_accuracy = model.evaluate(test_batches, verbose=1)\n",
    "print('Baseline test accuracy: ', baseline_model_accuracy)\n",
    "\n",
    "keras_file = './test.h5'\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to: ', keras_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对Baseline进行quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:08:06.064184Z",
     "start_time": "2020-06-01T07:08:03.655164Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "quantize_layer (QuantizeLaye (None, 32, 32, 3)         3         \n",
      "_________________________________________________________________\n",
      "quant_block1_conv1 (Quantize (None, 32, 32, 64)        1923      \n",
      "_________________________________________________________________\n",
      "quant_block1_conv2 (Quantize (None, 32, 32, 64)        37059     \n",
      "_________________________________________________________________\n",
      "quant_block1_pool (QuantizeW (None, 16, 16, 64)        1         \n",
      "_________________________________________________________________\n",
      "quant_block2_conv1 (Quantize (None, 16, 16, 128)       74115     \n",
      "_________________________________________________________________\n",
      "quant_block2_conv2 (Quantize (None, 16, 16, 128)       147843    \n",
      "_________________________________________________________________\n",
      "quant_block2_pool (QuantizeW (None, 8, 8, 128)         1         \n",
      "_________________________________________________________________\n",
      "quant_block3_conv1 (Quantize (None, 8, 8, 256)         295683    \n",
      "_________________________________________________________________\n",
      "quant_block3_conv2 (Quantize (None, 8, 8, 256)         590595    \n",
      "_________________________________________________________________\n",
      "quant_block3_conv3 (Quantize (None, 8, 8, 256)         590595    \n",
      "_________________________________________________________________\n",
      "quant_block3_pool (QuantizeW (None, 4, 4, 256)         1         \n",
      "_________________________________________________________________\n",
      "quant_block4_conv1 (Quantize (None, 4, 4, 512)         1181187   \n",
      "_________________________________________________________________\n",
      "quant_block4_conv2 (Quantize (None, 4, 4, 512)         2360835   \n",
      "_________________________________________________________________\n",
      "quant_block4_conv3 (Quantize (None, 4, 4, 512)         2360835   \n",
      "_________________________________________________________________\n",
      "quant_block4_pool (QuantizeW (None, 2, 2, 512)         1         \n",
      "_________________________________________________________________\n",
      "quant_block5_conv1 (Quantize (None, 2, 2, 512)         2360835   \n",
      "_________________________________________________________________\n",
      "quant_block5_conv2 (Quantize (None, 2, 2, 512)         2360835   \n",
      "_________________________________________________________________\n",
      "quant_block5_conv3 (Quantize (None, 2, 2, 512)         2360835   \n",
      "_________________________________________________________________\n",
      "quant_block5_pool (QuantizeW (None, 1, 1, 512)         1         \n",
      "_________________________________________________________________\n",
      "quant_global_average_pooling (None, 512)               3         \n",
      "_________________________________________________________________\n",
      "quant_fc1 (QuantizeWrapper)  (None, 128)               65669     \n",
      "_________________________________________________________________\n",
      "quant_predictions (QuantizeW (None, 10)                1295      \n",
      "=================================================================\n",
      "Total params: 14,790,150\n",
      "Trainable params: 14,781,642\n",
      "Non-trainable params: 8,508\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练Baseline_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:18:37.207404Z",
     "start_time": "2020-06-01T07:08:06.065156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 1.6934 - accuracy: 0.7798\n",
      "Epoch 2/20\n",
      "196/196 [==============================] - 31s 156ms/step - loss: 1.5625 - accuracy: 0.9037\n",
      "Epoch 3/20\n",
      "196/196 [==============================] - 31s 156ms/step - loss: 1.5249 - accuracy: 0.9391\n",
      "Epoch 4/20\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 1.5128 - accuracy: 0.9502\n",
      "Epoch 5/20\n",
      "196/196 [==============================] - 30s 156ms/step - loss: 1.5065 - accuracy: 0.9560\n",
      "Epoch 6/20\n",
      "196/196 [==============================] - 31s 156ms/step - loss: 1.5049 - accuracy: 0.9574\n",
      "Epoch 7/20\n",
      "196/196 [==============================] - 31s 156ms/step - loss: 1.5049 - accuracy: 0.9573\n",
      "Epoch 8/20\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 1.5039 - accuracy: 0.9584\n",
      "Epoch 9/20\n",
      "196/196 [==============================] - 31s 156ms/step - loss: 1.5031 - accuracy: 0.9590\n",
      "Epoch 10/20\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 1.5043 - accuracy: 0.9575\n",
      "Epoch 11/20\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 1.5020 - accuracy: 0.9602\n",
      "Epoch 12/20\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 1.5026 - accuracy: 0.9594\n",
      "Epoch 13/20\n",
      "196/196 [==============================] - 31s 156ms/step - loss: 1.5018 - accuracy: 0.9603\n",
      "Epoch 14/20\n",
      "196/196 [==============================] - 31s 157ms/step - loss: 1.5019 - accuracy: 0.9602\n",
      "Epoch 15/20\n",
      "196/196 [==============================] - 31s 156ms/step - loss: 1.5016 - accuracy: 0.9604\n",
      "Epoch 16/20\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 1.5016 - accuracy: 0.9605\n",
      "Epoch 17/20\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 1.5016 - accuracy: 0.9602\n",
      "Epoch 18/20\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 1.5016 - accuracy: 0.9605\n",
      "Epoch 19/20\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 1.5014 - accuracy: 0.9606\n",
      "Epoch 20/20\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 1.5014 - accuracy: 0.9607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff3ec4d7b38>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "epochs = 20\n",
    "\n",
    "q_aware_model.fit(train_batches,\n",
    "                     batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比Baseline和quantized之后的test acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:18:40.329253Z",
     "start_time": "2020-06-01T07:18:37.208168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.8348000049591064\n",
      "Quant test accuracy: 0.8457000255584717\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_batches, verbose=0)\n",
    "\n",
    "_, q_aware_model_accuracy = q_aware_model.evaluate(\n",
    "   test_batches, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Quant test accuracy:', q_aware_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create quantized model for TFLite backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:18:43.463732Z",
     "start_time": "2020-06-01T07:18:40.330196Z"
    }
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存int8的TFLite模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:18:43.484243Z",
     "start_time": "2020-06-01T07:18:43.464953Z"
    }
   },
   "outputs": [],
   "source": [
    "tflite_model_quant_file = './int8.tflite'\n",
    "with open(tflite_model_quant_file, 'wb') as f:\n",
    "    f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 封装函数用于评估TFLite模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:18:43.490025Z",
     "start_time": "2020-06-01T07:18:43.485259Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    labels = []\n",
    "    for i, (image, label) in enumerate(raw_test):\n",
    "        if i % 1000 == 0:\n",
    "          print('Evaluated on {n} results so far.'.format(n=i))\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        image, label = convert(image, label)\n",
    "    #     print(label.numpy())\n",
    "        test_image = np.expand_dims(image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "        labels.append(label.numpy())\n",
    "\n",
    "    print('\\n')\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    accuracy = (prediction_digits == labels).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比Quantized之后的TF和TFLite模型的test acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T07:21:26.486673Z",
     "start_time": "2020-06-01T07:18:43.491097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Quant TFLite test_accuracy: 0.8473\n",
      "Quant TF test accuracy: 0.8457000255584717\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('Quant TFLite test_accuracy:', test_accuracy)\n",
    "print('Quant TF test accuracy:', q_aware_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "498.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
