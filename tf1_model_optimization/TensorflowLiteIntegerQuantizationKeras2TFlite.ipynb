{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:37.214801Z",
     "start_time": "2020-05-25T12:37:35.771099Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 as Net  # 从keras模型库里导入预定义好的模型\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_io # 用于计算图的读写\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 声明一个MobielnetV2实例，加载的是在ImageNet上预训练过的模型，使用的是keras的.h5模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:39.704198Z",
     "start_time": "2020-05-25T12:37:37.215889Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存MobilenetV2到model文件下，命名为mobilenetv2.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:39.912064Z",
     "start_time": "2020-05-25T12:37:39.705277Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs('./model', exist_ok=True)  # 使用这种方式有个好处，如果已经存在model文件夹了，不会报错\n",
    "\n",
    "model.save('./model/mobilenetv2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear any previous session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:39.915725Z",
     "start_time": "2020-05-25T12:37:39.912932Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一些参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:39.927599Z",
     "start_time": "2020-05-25T12:37:39.916578Z"
    }
   },
   "outputs": [],
   "source": [
    "save_pb_dir = './model'\n",
    "model_fname = './model/mobilenetv2.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 封装freeze函数，用于把.h5模型文件转换成.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:39.933958Z",
     "start_time": "2020-05-25T12:37:39.928552Z"
    }
   },
   "outputs": [],
   "source": [
    "def freeze_graph(graph, session, output, save_pb_dir='.', save_pb_name='fp32_frozen_graph.pb', save_pb_as_text=False):\n",
    "    with graph.as_default():\n",
    "        graphdef_inf = tf.graph_util.remove_training_nodes(graph.as_graph_def())\n",
    "        # 把变量转化成常量\n",
    "        graphdef_frozen = tf.graph_util.convert_variables_to_constants(session, graphdef_inf, output)\n",
    "        # 保存fp32_frozen_graph.pb到本地\n",
    "        graph_io.write_graph(graphdef_frozen, save_pb_dir, save_pb_name, as_text=save_pb_as_text)\n",
    "        return graphdef_frozen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This line must be executed before loading Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:39.943165Z",
     "start_time": "2020-05-25T12:37:39.935259Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载mobilenetv2.h5模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.254499Z",
     "start_time": "2020-05-25T12:37:39.944226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成一个Session，里面包含了上面加载过来的模型结构和参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.366309Z",
     "start_time": "2020-05-25T12:37:41.255571Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.backend' has no attribute 'get_session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f0856215de04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.backend' has no attribute 'get_session'"
     ]
    }
   ],
   "source": [
    "session = tf.keras.backend.get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入和输出节点收集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.367367Z",
     "start_time": "2020-05-25T12:37:35.783Z"
    }
   },
   "outputs": [],
   "source": [
    "input_names = [t.op.name for t in model.inputs]\n",
    "output_names = [t.op.name for t in model.outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.367767Z",
     "start_time": "2020-05-25T12:37:35.785Z"
    }
   },
   "outputs": [],
   "source": [
    "print(input_names, output_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行模型的freeze操作，保存fp32_frozen_graph.pb，并返回fp32_frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.368155Z",
     "start_time": "2020-05-25T12:37:35.787Z"
    }
   },
   "outputs": [],
   "source": [
    "fp32_frozen_graph = freeze_graph(session.graph, session, output_names, save_pb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把fp32_frozen_graph.pb转化成fp32_frozen_graph.tflite，相当于FP32->FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.368548Z",
     "start_time": "2020-05-25T12:37:35.789Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_def_file = './model/fp32_frozen_graph.pb'\n",
    "input_arrays = ['input_1']  # 输入节点\n",
    "output_arrays = ['Logits/Softmax']  # 输出节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.368940Z",
     "start_time": "2020-05-25T12:37:35.790Z"
    }
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays) # 得到converter对象\n",
    "tflite_model = converter.convert() # 进行转换\n",
    "open('./model/fp32_frozen_graph.tflite', 'wb').write(tflite_model) # 保存fp32_frozen_graph.tflite到本地"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把fp32_frozen_graph.pb转化成int8_frozen_graph.tflite，相当于FP32->INT8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载一张图片用于calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.369334Z",
     "start_time": "2020-05-25T12:37:35.793Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = './elephant.jpg'\n",
    "\n",
    "image_size = [224, 224, 3]\n",
    "img = image.load_img(img_path, target_size=image_size[:2])\n",
    "x = image.img_to_array(img)  # 转换成numpy array\n",
    "x = np.expand_dims(x, axis=0) # 添加一个维度，变成[batch_size, H, W, C]\n",
    "x = preprocess_input(x) # 对图片进行预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一些参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.369920Z",
     "start_time": "2020-05-25T12:37:35.795Z"
    }
   },
   "outputs": [],
   "source": [
    "num_calibration_batches = 2\n",
    "BATCH_SIZE = 1\n",
    "batched_input = np.zeros((BATCH_SIZE * num_calibration_batches, 224, 224, 3), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得到batched_input,用于calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.370392Z",
     "start_time": "2020-05-25T12:37:35.797Z"
    }
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # 这种设置的好处是，tensorflow不会一次性占用全部显存，而是用多少占多少\n",
    "with tf.Session(graph=tf.Graph(), config=config) as sess:\n",
    "    next_element = tf.convert_to_tensor(x)  # 把numpy array转换成tensor\n",
    "    for i in range(num_calibration_batches):\n",
    "        print(batched_input[i*BATCH_SIZE:(i+1)*BATCH_SIZE, :].shape, sess.run(next_element).shape)\n",
    "        batched_input[i*BATCH_SIZE:(i+1)*BATCH_SIZE, :] = sess.run(next_element)\n",
    "\n",
    "print('Calibration data shape: ', batched_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 封装calibration_input函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.370926Z",
     "start_time": "2020-05-25T12:37:35.799Z"
    }
   },
   "outputs": [],
   "source": [
    "def calibration_input_fn_gen():\n",
    "    for i in range(num_calibration_batches):\n",
    "        yield [batched_input[i*BATCH_SIZE:(i+1)*BATCH_SIZE, :]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行FP32->INT8的转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.371345Z",
     "start_time": "2020-05-25T12:37:35.801Z"
    }
   },
   "outputs": [],
   "source": [
    "graph_def_file = './model/fp32_frozen_graph.pb'\n",
    "input_arrays = ['input_1']\n",
    "output_arrays = ['Logits/Softmax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.371918Z",
     "start_time": "2020-05-25T12:37:35.802Z"
    }
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays) # 得到converter对象\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = calibration_input_fn_gen # 引入用于calibration的batch数据\n",
    "tflite_model = converter.convert() # 进行转换\n",
    "open('./model/int8_frozen_graph.tflite', 'wb').write(tflite_model) # 把int8_frozen_graph.tflite写到本地"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推断函数封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.372777Z",
     "start_time": "2020-05-25T12:37:35.804Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfLiteInference(input_details, interpreter, output_details, x):\n",
    "    interpreter.set_tensor(input_details[0]['index'], x) # 设置输入\n",
    "    \n",
    "    interpreter.invoke() # 执行推断\n",
    "    \n",
    "    output_data = interpreter.get_tensor(output_details[0]['index']) # 设置输出\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试FP32的.tflite的FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.373236Z",
     "start_time": "2020-05-25T12:37:35.806Z"
    }
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='./model/fp32_frozen_graph.tflite') # 得到interpreter对象\n",
    "interpreter.allocate_tensors() # 为tensor分配内存\n",
    "\n",
    "input_details = interpreter.get_input_details() # 获取输入\n",
    "output_details = interpreter.get_output_details() # 获取输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.373662Z",
     "start_time": "2020-05-25T12:37:35.808Z"
    }
   },
   "outputs": [],
   "source": [
    "times =[]\n",
    "output_data = tfLiteInference(input_details, interpreter, output_details, x) # 执行推断\n",
    "\n",
    "print('Predicted: ', decode_predictions(output_data, top=3)[0])\n",
    "\n",
    "# 获取FPS\n",
    "for i in range(2000):\n",
    "    start_time = time.time()\n",
    "    # 此处的x输入来源于上面的加载一张图片用于calibration\n",
    "    output_data = tfLiteInference(input_details, interpreter, output_details, x)\n",
    "    delta = (time.time() - start_time)\n",
    "    times.append(delta)\n",
    "mean_delta = np.array(times).mean()\n",
    "fps = 1 / mean_delta\n",
    "print('average(sec):{:.2f}, fps:{:.2f}'.format(mean_delta, fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T03:22:06.758743Z",
     "start_time": "2020-05-14T03:22:06.756474Z"
    }
   },
   "source": [
    "我发现Tensorflow Lite的模型在不同平台上，性能不一样，在微星台式机上是86FPS, 在微星笔记本上是64FPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试INT8的.tflite的FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.374172Z",
     "start_time": "2020-05-25T12:37:35.809Z"
    }
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='./model/int8_frozen_graph.tflite') # 得到interpreter对象\n",
    "interpreter.allocate_tensors() # 为tensor分配内存\n",
    "\n",
    "input_details = interpreter.get_input_details() # 获取输入\n",
    "output_details = interpreter.get_output_details() # 获取输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T12:37:41.374795Z",
     "start_time": "2020-05-25T12:37:35.811Z"
    }
   },
   "outputs": [],
   "source": [
    "times = []\n",
    "\n",
    "output_data = tfLiteInference(input_details, interpreter, output_details, x) # 执行推断\n",
    "\n",
    "print('Predicted: ', decode_predictions(output_data, top=3)[0])\n",
    "\n",
    "# 获取FPS\n",
    "for i in range(20):\n",
    "    start_time = time.time()\n",
    "    # 此处的x输入来源于上面的加载一张图片用于calibration\n",
    "    output_data = tfLiteInference(input_details, interpreter, output_details, x)\n",
    "    delta = (time.time() - start_time)\n",
    "    times.append(delta)\n",
    "mean_delta = np.array(times).mean()\n",
    "fps = 1 / mean_delta\n",
    "print('average(sec):{:.2f}, fps:{:.2f}'.format(mean_delta, fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
