{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:23.828763Z",
     "start_time": "2020-05-17T11:09:22.994373Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow_model_optimization # 引入tensorflow自带的优化接口\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity  # 该接口只用于剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:24.286341Z",
     "start_time": "2020-05-17T11:09:23.829933Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() # 选用的是cifar10数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把数据集的INT8转换成Float32类型，对标签进行独热编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:24.466951Z",
     "start_time": "2020-05-17T11:09:24.287369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255  # 缩放到[0,1]\n",
    "x_test /= 255\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "num_classes = 10  # cifar10属于10分类问题\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes = 10) # 对标签进行独热编码\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 展示编码后的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:24.473332Z",
     "start_time": "2020-05-17T11:09:24.467753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建VGG16模型，用于cifar10分类，代码参考自keras github的VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型的一些参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:24.481710Z",
     "start_time": "2020-05-17T11:09:24.474123Z"
    }
   },
   "outputs": [],
   "source": [
    "backend = tf.keras.backend\n",
    "layers = tf.keras.layers\n",
    "models = tf.keras.models\n",
    "keras_utils = tf.keras.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:24.487861Z",
     "start_time": "2020-05-17T11:09:24.482593Z"
    }
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
    "                       'releases/download/v0.1/'\n",
    "                       'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')  # 此处的预训练模型不带全连接层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建VGG16模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:24.500229Z",
     "start_time": "2020-05-17T11:09:24.489362Z"
    }
   },
   "outputs": [],
   "source": [
    "def VGG16(include_top=False,\n",
    "         weights='imagenet',\n",
    "         input_tensor=None,\n",
    "         input_shape=(32, 32, 3),\n",
    "         pooling='avg',\n",
    "         classes=10,\n",
    "         **kwargs):\n",
    "    img_input = layers.Input(shape=input_shape)  # 输入节点\n",
    "    \n",
    "    # Block 1\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(img_input)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    if pooling == 'avg':\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(128, activation='relu', name='fc1')(x)\n",
    "        x = layers.Dense(classes, activation='softmax', name='predictions')(x) # 此处是10分类，而不是ImageNet的1000分类\n",
    "    \n",
    "    inputs = img_input  # 输入节点, x是输出节点\n",
    "    model = models.Model(inputs, x , name='vgg16')  # 生成一个Model, 需要指定输入和输出\n",
    "    \n",
    "    weights_path = keras_utils.get_file(\n",
    "        'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',  # 此处加载的是不存在全连接层的预训练模型\n",
    "        WEIGHTS_PATH_NO_TOP,\n",
    "        cache_subdir='models',\n",
    "        file_hash='6d6bbae143d832006294945121d1f1fc')\n",
    "    model.load_weights(weights_path, by_name=True)  # 加载在ImageNet上预训练过的模型，注意by_name参数很有用\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例化一个vgg16对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:25.337370Z",
     "start_time": "2020-05-17T11:09:24.501379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "vgg16 = VGG16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看模型的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:25.344201Z",
     "start_time": "2020-05-17T11:09:25.338258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 14,781,642\n",
      "Trainable params: 14,781,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对模型进行剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置pruning参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:25.350705Z",
     "start_time": "2020-05-17T11:09:25.344994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End step: 3910\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "num_train_samples = x_train.shape[0]\n",
    "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
    "print('End step: ' + str(end_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:25.356891Z",
     "start_time": "2020-05-17T11:09:25.351618Z"
    }
   },
   "outputs": [],
   "source": [
    "pruning_params = {\n",
    "    'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.5,  # 起始稀疏度\n",
    "                                                final_sparsity=0.9,  # 最终稀疏度\n",
    "                                                begin_step=2000,  # 从哪一个step开始剪枝\n",
    "                                                end_step=end_step,  # 剪枝结束的step\n",
    "                                                frequency=100)  # 每100个step进行剪枝一次\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得到剪枝后的vgg16模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:27.272630Z",
     "start_time": "2020-05-17T11:09:25.357792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:199: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.debugging.assert_greater_equal is deprecated. Please use tf.compat.v1.debugging.assert_greater_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_schedule.py:240: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/keras/compat.py:25: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vgg16_pruned = sparsity.prune_low_magnitude(vgg16, **pruning_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看剪枝后的模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:27.280163Z",
     "start_time": "2020-05-17T11:09:27.273618Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block1_c (None, 32, 32, 64)        3522      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block1_c (None, 32, 32, 64)        73794     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block1_p (None, 16, 16, 64)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block2_c (None, 16, 16, 128)       147586    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block2_c (None, 16, 16, 128)       295042    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block2_p (None, 8, 8, 128)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block3_c (None, 8, 8, 256)         590082    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block3_c (None, 8, 8, 256)         1179906   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block3_c (None, 8, 8, 256)         1179906   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block3_p (None, 4, 4, 256)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block4_c (None, 4, 4, 512)         2359810   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block4_c (None, 4, 4, 512)         4719106   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block4_c (None, 4, 4, 512)         4719106   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block4_p (None, 2, 2, 512)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block5_c (None, 2, 2, 512)         4719106   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block5_c (None, 2, 2, 512)         4719106   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block5_c (None, 2, 2, 512)         4719106   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_block5_p (None, 1, 1, 512)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_global_a (None, 512)               1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_fc1 (Pru (None, 128)               131202    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_predicti (None, 10)                2572      \n",
      "=================================================================\n",
      "Total params: 29,558,958\n",
      "Trainable params: 14,781,642\n",
      "Non-trainable params: 14,777,316\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_pruned.summary()  # 多了一层pruning wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置Logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:27.294118Z",
     "start_time": "2020-05-17T11:09:27.281529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing training logs to /tmp/tmpluj0h2dp\n"
     ]
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "print('writing training logs to ' + logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:27.334911Z",
     "start_time": "2020-05-17T11:09:27.296279Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg16_pruned.compile(\n",
    "    loss = tf.keras.losses.categorical_crossentropy, # 分类模型一般用这个损失函数\n",
    "    optimizer = 'adam',  # 采用的优化器\n",
    "    metrics = ['accuracy'] # 此处只评估准确率\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:27.337756Z",
     "start_time": "2020-05-17T11:09:27.335865Z"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    sparsity.UpdatePruningStep(),\n",
    "    sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:29.871843Z",
     "start_time": "2020-05-17T11:09:27.338701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 32s 649us/sample - loss: 1.9609 - acc: 0.2412 - val_loss: 1.6188 - val_acc: 0.3694\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 26s 512us/sample - loss: 1.2181 - acc: 0.5446 - val_loss: 1.0506 - val_acc: 0.6344\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 26s 511us/sample - loss: 0.8708 - acc: 0.6965 - val_loss: 0.7844 - val_acc: 0.7343\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 26s 511us/sample - loss: 0.6896 - acc: 0.7662 - val_loss: 0.7738 - val_acc: 0.7432\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 26s 513us/sample - loss: 0.5661 - acc: 0.8108 - val_loss: 0.6477 - val_acc: 0.7928\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 26s 523us/sample - loss: 0.4356 - acc: 0.8574 - val_loss: 0.6286 - val_acc: 0.8012\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 26s 523us/sample - loss: 0.3822 - acc: 0.8732 - val_loss: 0.6841 - val_acc: 0.7941\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 26s 524us/sample - loss: 0.3703 - acc: 0.8802 - val_loss: 0.6375 - val_acc: 0.7968\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 26s 523us/sample - loss: 0.3197 - acc: 0.8953 - val_loss: 0.5950 - val_acc: 0.8178\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 26s 524us/sample - loss: 0.2164 - acc: 0.9285 - val_loss: 0.6483 - val_acc: 0.8149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa84a27b3d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_pruned.fit(x_train, y_train,\n",
    "                batch_size = 128,\n",
    "                epochs = epochs,\n",
    "                verbose=1,\n",
    "                callbacks = callbacks,\n",
    "                validation_data = (x_test, y_test)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估模型损失值和正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:29.873095Z",
     "start_time": "2020-05-17T11:09:23.018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.605324596953392\n",
      "Test accuracy:  0.8289\n"
     ]
    }
   ],
   "source": [
    "score = vgg16_pruned.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对模型去除pruning wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:29.873550Z",
     "start_time": "2020-05-17T11:09:23.020Z"
    }
   },
   "outputs": [],
   "source": [
    "final_model = sparsity.strip_pruning(vgg16_pruned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:29.874086Z",
     "start_time": "2020-05-17T11:09:23.021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pruned model to:  /tmp/tmpxmjv4q47.h5\n"
     ]
    }
   ],
   "source": [
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving pruned model to: ', pruned_keras_file)\n",
    "tf.keras.models.save_model(final_model, pruned_keras_file, include_optimizer=False)  # 这里只保存模型权重，所以optimizer=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对剪枝模型进行压缩，对未剪枝模型进行压缩，对比两者大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:29.874684Z",
     "start_time": "2020-05-17T11:09:23.023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the pruned model before compression: 56.45 Mb\n",
      "Size of the pruned model after compression: 10.84 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip3 = tempfile.mkstemp('.zip')\n",
    "with zipfile.ZipFile(zip3, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(pruned_keras_file)\n",
    "print(\"Size of the pruned model before compression: %.2f Mb\" \n",
    "      % (os.path.getsize(pruned_keras_file) / float(2**20)))\n",
    "print(\"Size of the pruned model after compression: %.2f Mb\" \n",
    "      % (os.path.getsize(zip3) / float(2**20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转化成FP32的.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:29.875209Z",
     "start_time": "2020-05-17T11:09:23.024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/lite/python/util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 30 variables.\n",
      "INFO:tensorflow:Converted 30 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "tflite_model_file = './sparse_cifar10.tflite'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(pruned_keras_file) # 获得converter对象\n",
    "tflite_model = converter.convert()  # 进行转换\n",
    "with open(tflite_model_file, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 封装TFLite模型准确率验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:29.875666Z",
     "start_time": "2020-05-17T11:09:23.026Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_model(interpreter, x_test, y_test):\n",
    "    total_seen = 0\n",
    "    num_correct = 0\n",
    "    \n",
    "    for img, label in zip(x_test, y_test):\n",
    "        inp = img.reshape((1, 32, 32, 3))\n",
    "        total_seen += 1\n",
    "        interpreter.set_tensor(input_index, inp)  # 获得输入\n",
    "        interpreter.invoke()  # 执行推断\n",
    "        predictions = interpreter.get_tensor(output_index) # 获取输出\n",
    "        \n",
    "        if np.argmax(predictions) == np.argmax(label):\n",
    "            num_correct += 1\n",
    "        \n",
    "        if total_seen % 1000 == 0:\n",
    "            print('Accuracy after %i images: %f' % (total_seen, float(num_correct) / float(total_seen)))\n",
    "    \n",
    "    return float(num_correct) / float(total_seen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转化成FP32的.tflite，我们发现模型没什么变化，只是存储格式发生了变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:29.876205Z",
     "start_time": "2020-05-17T11:09:23.027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the tflite model before compression: 56.39 Mb\n",
      "Size of the tflite model after compression: 10.76 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip_tflite = tempfile.mkstemp('.zip')\n",
    "with zipfile.ZipFile(zip_tflite, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(tflite_model_file)\n",
    "print(\"Size of the tflite model before compression: %.2f Mb\" \n",
    "      % (os.path.getsize(tflite_model_file) / float(2**20)))\n",
    "print(\"Size of the tflite model after compression: %.2f Mb\" \n",
    "      % (os.path.getsize(zip_tflite) / float(2**20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证FP32的.tflite模型准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:29.876865Z",
     "start_time": "2020-05-17T11:09:23.029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 1000 images: 0.840000\n",
      "Accuracy after 2000 images: 0.837500\n",
      "Accuracy after 3000 images: 0.830000\n",
      "Accuracy after 4000 images: 0.833500\n",
      "Accuracy after 5000 images: 0.833600\n",
      "Accuracy after 6000 images: 0.832833\n",
      "Accuracy after 7000 images: 0.832000\n",
      "Accuracy after 8000 images: 0.828875\n",
      "Accuracy after 9000 images: 0.828778\n",
      "Accuracy after 10000 images: 0.828900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8289"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))  # 获取interpreter对象\n",
    "interpreter.allocate_tensors() # 为tensor分配内存\n",
    "input_index = interpreter.get_input_details()[0][\"index\"] # 获取输入\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]  # 获取输出\n",
    "\n",
    "eval_model(interpreter, x_test, y_test)  # 执行评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转化过程中引入weight_quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:29.877573Z",
     "start_time": "2020-05-17T11:09:23.031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "INFO:tensorflow:Froze 30 variables.\n",
      "INFO:tensorflow:Converted 30 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "tflite_quant_model_file = './sparse_cifar10_quant.tflite'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(pruned_keras_file) # 获得converter对象\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_quant_model = converter.convert() # 进行转换\n",
    "with open(tflite_quant_model_file, 'wb') as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对比weight_quantization前后模型体积变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:29.878109Z",
     "start_time": "2020-05-17T11:09:23.033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the tflite model before compression: 14.12 Mb\n",
      "Size of the tflite model after compression: 2.52 Mb\n"
     ]
    }
   ],
   "source": [
    "_, zip_tflite = tempfile.mkstemp('.zip')\n",
    "with zipfile.ZipFile(zip_tflite, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "  f.write(tflite_quant_model_file)\n",
    "print(\"Size of the tflite model before compression: %.2f Mb\" \n",
    "      % (os.path.getsize(tflite_quant_model_file) / float(2**20)))\n",
    "print(\"Size of the tflite model after compression: %.2f Mb\" \n",
    "      % (os.path.getsize(zip_tflite) / float(2**20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证tflite模型准确率,查看weight quantization后，下降了多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T11:09:29.878712Z",
     "start_time": "2020-05-17T11:09:23.034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 1000 images: 0.839000\n",
      "Accuracy after 2000 images: 0.837000\n",
      "Accuracy after 3000 images: 0.830000\n",
      "Accuracy after 4000 images: 0.833000\n",
      "Accuracy after 5000 images: 0.832800\n",
      "Accuracy after 6000 images: 0.832167\n",
      "Accuracy after 7000 images: 0.831286\n",
      "Accuracy after 8000 images: 0.827500\n",
      "Accuracy after 9000 images: 0.827444\n",
      "Accuracy after 10000 images: 0.827400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8274"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_quant_model_file)) # 获得interpreter对象\n",
    "interpreter.allocate_tensors() # 为tensor分配内存\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]  # 获取输入\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]  #  获取输出\n",
    "\n",
    "eval_model(interpreter, x_test, y_test)  # 执行评估函数"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
