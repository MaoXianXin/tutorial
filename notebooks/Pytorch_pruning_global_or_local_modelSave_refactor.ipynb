{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[文章参考来源](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#serializing-a-pruned-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.715750Z",
     "start_time": "2020-05-12T10:49:46.488055Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.721389Z",
     "start_time": "2020-05-12T10:49:46.716845Z"
    }
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)  #输入1通道，输出6通道，kernel_size=3\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        # 全连接层接受的是二维输入，所以要把[batch_size,C,H,W]转化成二维[batch_size,C*H*W]，.nelement()的作用是统计array里元素个数\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 声明一个LeNet网络的实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.730952Z",
     "start_time": "2020-05-12T10:49:46.722380Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.740162Z",
     "start_time": "2020-05-12T10:49:46.731920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.746325Z",
     "start_time": "2020-05-12T10:49:46.740904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测conv1,其中包含了weight和bias,因为还没使用conv1,所以没有buffers产生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.751530Z",
     "start_time": "2020-05-12T10:49:46.747151Z"
    }
   },
   "outputs": [],
   "source": [
    "module = model.conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先说一下后面会用到的几个概念，model.conv1.weight这里的weight是属性，运行prune操作之后产生的稀疏权重会存储在这里，然后我们需要运行prune.remove()操作，才能让model.conv1.weight和model.conv1.named_parameters()的显示结果变成一样\n",
    "\n",
    "model.conv1.named_buffers()运行操作后，生产的mask会在这里\n",
    "\n",
    "model.conv1.named_parameters()模型参数的存储位置，这里面的值会跟随torch.save存储到本地的.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 观察module或者说是conv1,我们发现了weight和bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.759046Z",
     "start_time": "2020-05-12T10:49:46.752908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-0.0898, -0.0485, -0.1099],\n",
       "            [-0.1332,  0.1818,  0.1453],\n",
       "            [ 0.0650, -0.0458, -0.3288]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0484,  0.1676, -0.0955],\n",
       "            [-0.0152,  0.0982,  0.3147],\n",
       "            [ 0.0366,  0.2182,  0.1500]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1811,  0.1072, -0.1571],\n",
       "            [ 0.1384,  0.1773, -0.1943],\n",
       "            [ 0.2540, -0.2687,  0.0157]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1855, -0.2887, -0.1619],\n",
       "            [-0.3159,  0.0956, -0.2672],\n",
       "            [ 0.2999,  0.2911,  0.2165]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3050, -0.0507,  0.2013],\n",
       "            [-0.0671,  0.0048, -0.1685],\n",
       "            [-0.0315,  0.2467, -0.1058]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1506, -0.2770,  0.2948],\n",
       "            [-0.1525,  0.1865,  0.3311],\n",
       "            [ 0.1968, -0.0494, -0.0923]]]], requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.3012,  0.3177,  0.2504, -0.0306, -0.1358, -0.1074],\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用weight属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.764441Z",
     "start_time": "2020-05-12T10:49:46.759991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.0898, -0.0485, -0.1099],\n",
       "          [-0.1332,  0.1818,  0.1453],\n",
       "          [ 0.0650, -0.0458, -0.3288]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0484,  0.1676, -0.0955],\n",
       "          [-0.0152,  0.0982,  0.3147],\n",
       "          [ 0.0366,  0.2182,  0.1500]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1811,  0.1072, -0.1571],\n",
       "          [ 0.1384,  0.1773, -0.1943],\n",
       "          [ 0.2540, -0.2687,  0.0157]]],\n",
       "\n",
       "\n",
       "        [[[-0.1855, -0.2887, -0.1619],\n",
       "          [-0.3159,  0.0956, -0.2672],\n",
       "          [ 0.2999,  0.2911,  0.2165]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3050, -0.0507,  0.2013],\n",
       "          [-0.0671,  0.0048, -0.1685],\n",
       "          [-0.0315,  0.2467, -0.1058]]],\n",
       "\n",
       "\n",
       "        [[[-0.1506, -0.2770,  0.2948],\n",
       "          [-0.1525,  0.1865,  0.3311],\n",
       "          [ 0.1968, -0.0494, -0.0923]]]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 因为还没使用过conv1,所以这里的buffer为空，调用prune之后你会发现差别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.769477Z",
     "start_time": "2020-05-12T10:49:46.765259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对conv1里的weight进行random_unstructured剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.776188Z",
     "start_time": "2020-05-12T10:49:46.770256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.random_unstructured(module, name='weight', amount=0.3) # 裁剪比例设置为0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 你可以发现这里的weight被重命名为weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.782598Z",
     "start_time": "2020-05-12T10:49:46.777009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.3012,  0.3177,  0.2504, -0.0306, -0.1358, -0.1074],\n",
       "         requires_grad=True)),\n",
       " ('weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-0.0898, -0.0485, -0.1099],\n",
       "            [-0.1332,  0.1818,  0.1453],\n",
       "            [ 0.0650, -0.0458, -0.3288]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0484,  0.1676, -0.0955],\n",
       "            [-0.0152,  0.0982,  0.3147],\n",
       "            [ 0.0366,  0.2182,  0.1500]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1811,  0.1072, -0.1571],\n",
       "            [ 0.1384,  0.1773, -0.1943],\n",
       "            [ 0.2540, -0.2687,  0.0157]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1855, -0.2887, -0.1619],\n",
       "            [-0.3159,  0.0956, -0.2672],\n",
       "            [ 0.2999,  0.2911,  0.2165]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3050, -0.0507,  0.2013],\n",
       "            [-0.0671,  0.0048, -0.1685],\n",
       "            [-0.0315,  0.2467, -0.1058]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1506, -0.2770,  0.2948],\n",
       "            [-0.1525,  0.1865,  0.3311],\n",
       "            [ 0.1968, -0.0494, -0.0923]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.conv1.weight这里的weight是属性，运行prune操作之后产生的稀疏权重会存储在这里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.788011Z",
     "start_time": "2020-05-12T10:49:46.783526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0898, -0.0000, -0.0000],\n",
       "          [-0.1332,  0.1818,  0.1453],\n",
       "          [ 0.0650, -0.0458, -0.3288]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0484,  0.1676, -0.0955],\n",
       "          [-0.0152,  0.0000,  0.0000],\n",
       "          [ 0.0366,  0.2182,  0.1500]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1811,  0.0000, -0.1571],\n",
       "          [ 0.0000,  0.1773, -0.1943],\n",
       "          [ 0.0000, -0.0000,  0.0157]]],\n",
       "\n",
       "\n",
       "        [[[-0.1855, -0.2887, -0.1619],\n",
       "          [-0.0000,  0.0956, -0.2672],\n",
       "          [ 0.2999,  0.2911,  0.2165]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3050, -0.0507,  0.2013],\n",
       "          [-0.0000,  0.0048, -0.0000],\n",
       "          [-0.0315,  0.0000, -0.1058]]],\n",
       "\n",
       "\n",
       "        [[[-0.1506, -0.0000,  0.2948],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [ 0.1968, -0.0494, -0.0923]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight   # 你会发现有些地方的值为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.conv1.named_buffers()运行prune操作后，生产的mask会在这里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.793663Z",
     "start_time": "2020-05-12T10:49:46.788845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight_mask',\n",
       "  tensor([[[[1., 0., 0.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [1., 0., 0.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 1.],\n",
       "            [0., 1., 1.],\n",
       "            [0., 0., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [0., 1., 1.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [0., 1., 0.],\n",
       "            [1., 0., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 1.],\n",
       "            [0., 0., 0.],\n",
       "            [1., 1., 1.]]]]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())  # 因为目前只对weight进行了prune，所以只有weight_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行L1_unstructured剪枝操作,不过这里的剪枝对象是conv1里的bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.799815Z",
     "start_time": "2020-05-12T10:49:46.794467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(module, name='bias', amount=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们可以发现bias变成了bias_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.806704Z",
     "start_time": "2020-05-12T10:49:46.801182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-0.0898, -0.0485, -0.1099],\n",
       "            [-0.1332,  0.1818,  0.1453],\n",
       "            [ 0.0650, -0.0458, -0.3288]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0484,  0.1676, -0.0955],\n",
       "            [-0.0152,  0.0982,  0.3147],\n",
       "            [ 0.0366,  0.2182,  0.1500]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1811,  0.1072, -0.1571],\n",
       "            [ 0.1384,  0.1773, -0.1943],\n",
       "            [ 0.2540, -0.2687,  0.0157]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1855, -0.2887, -0.1619],\n",
       "            [-0.3159,  0.0956, -0.2672],\n",
       "            [ 0.2999,  0.2911,  0.2165]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3050, -0.0507,  0.2013],\n",
       "            [-0.0671,  0.0048, -0.1685],\n",
       "            [-0.0315,  0.2467, -0.1058]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1506, -0.2770,  0.2948],\n",
       "            [-0.1525,  0.1865,  0.3311],\n",
       "            [ 0.1968, -0.0494, -0.0923]]]], requires_grad=True)),\n",
       " ('bias_orig',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.3012,  0.3177,  0.2504, -0.0306, -0.1358, -0.1074],\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生了bias_mask，这样子的话conv1里的weight和bias都进行了剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.812169Z",
     "start_time": "2020-05-12T10:49:46.807725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight_mask',\n",
       "  tensor([[[[1., 0., 0.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [1., 0., 0.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 1.],\n",
       "            [0., 1., 1.],\n",
       "            [0., 0., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [0., 1., 1.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [0., 1., 0.],\n",
       "            [1., 0., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 1.],\n",
       "            [0., 0., 0.],\n",
       "            [1., 1., 1.]]]])),\n",
       " ('bias_mask', tensor([1., 1., 1., 0., 1., 0.]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行ln_structured剪枝，注意看输出的weight,都是一整个channel为0的，剪枝的话，是可以连续剪枝的，这里是第二次对conv1里的weight进行剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.817347Z",
     "start_time": "2020-05-12T10:49:46.813094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.ln_structured(module, name='weight', amount=0.5, n=2, dim=0)\n",
    "# as we can verify, this will zero out all the connections corresponding to 50%(3 out of 6) of the channels,\n",
    "# while preserving the action of the previous mask\n",
    "# removing the specified amount of (currently unpruned) channels along the specified dim with the lowest L``n``-norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the forward pass to work without modification, the weight attribute needs to exist. The pruning techniques implemented in torch.nn.utils.prune compute the pruned version of the weight(by combining the mask with the original parameter) and store them in the attribute weight. Note, this is no longer a parameter of the module, it is now simply an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.826133Z",
     "start_time": "2020-05-12T10:49:46.818109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0898, -0.0000, -0.0000],\n",
       "          [-0.1332,  0.1818,  0.1453],\n",
       "          [ 0.0650, -0.0458, -0.3288]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.1855, -0.2887, -0.1619],\n",
       "          [-0.0000,  0.0956, -0.2672],\n",
       "          [ 0.2999,  0.2911,  0.2165]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.1506, -0.0000,  0.2948],\n",
       "          [-0.0000,  0.0000,  0.0000],\n",
       "          [ 0.1968, -0.0494, -0.0923]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.831474Z",
     "start_time": "2020-05-12T10:49:46.827803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prune.remove之后，我们发现weight_orig变成了weight, 其实就是把module.weight的值赋值给了weight_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行prune.remove的作用，to make the pruning permanent, remove the re-parametrization in terms of weight_orig and weight_mask, and remove the forward_pre_hook, we can use the remove functionality from torch.nn.utils.prune. Note that this doesn't undo the pruning, as if it never happened. it simply makes it permanent, instead, by reassigning the parameter weight to the model parameters, in its pruned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.837745Z",
     "start_time": "2020-05-12T10:49:46.832355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.remove(module, 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们发现weight_orig变成了weight，而且数值也发生了变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.844779Z",
     "start_time": "2020-05-12T10:49:46.838529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias_orig',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.3012,  0.3177,  0.2504, -0.0306, -0.1358, -0.1074],\n",
       "         requires_grad=True)),\n",
       " ('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-0.0898, -0.0000, -0.0000],\n",
       "            [-0.1332,  0.1818,  0.1453],\n",
       "            [ 0.0650, -0.0458, -0.3288]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0000,  0.0000, -0.0000],\n",
       "            [-0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0000,  0.0000, -0.0000],\n",
       "            [ 0.0000,  0.0000, -0.0000],\n",
       "            [ 0.0000, -0.0000,  0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1855, -0.2887, -0.1619],\n",
       "            [-0.0000,  0.0956, -0.2672],\n",
       "            [ 0.2999,  0.2911,  0.2165]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0000, -0.0000,  0.0000],\n",
       "            [-0.0000,  0.0000, -0.0000],\n",
       "            [-0.0000,  0.0000, -0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1506, -0.0000,  0.2948],\n",
       "            [-0.0000,  0.0000,  0.0000],\n",
       "            [ 0.1968, -0.0494, -0.0923]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## buffers里的weight_mask不在了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.849786Z",
     "start_time": "2020-05-12T10:49:46.846597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias_mask', tensor([1., 1., 1., 0., 1., 0.]))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prunning multiple parameters in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.855335Z",
     "start_time": "2020-05-12T10:49:46.850712Z"
    }
   },
   "outputs": [],
   "source": [
    "new_model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.916045Z",
     "start_time": "2020-05-12T10:49:46.856220Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, module in new_model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.2)\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.919249Z",
     "start_time": "2020-05-12T10:49:46.916845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(new_model.named_buffers()).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so far, we only looked at what is usually referred to as \"local\" pruning, the practice of pruning tensors in a model one by one, by comparing the statisitcs(weight magnitude, activation, gradient) of each entry exclusively to the other entries in that tensor. however, a common and perhaps more powerful technique is to prune the model all at once, by removing(for example) the lowest 20% of connections across the whole model, instead of removing the lowest 20% of connections in each layer. this is likely to result in different pruning percentages per layer. let's ses how to do that using global_unstructured from torch.nn.utils.prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.925089Z",
     "start_time": "2020-05-12T10:49:46.920027Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设定要剪枝的对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.930009Z",
     "start_time": "2020-05-12T10:49:46.925981Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    "    (model.fc3, 'weight')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:46.984072Z",
     "start_time": "2020-05-12T10:49:46.930766Z"
    }
   },
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看每层剪枝比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:47.013817Z",
     "start_time": "2020-05-12T10:49:46.984954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1.weight: 12.96%\n",
      "Sparsity in conv2.weight: 25.12%\n",
      "Sparsity in fc1.weight: 77.30%\n",
      "Sparsity in fc2.weight: 42.49%\n",
      "Sparsity in fc3.weight: 32.62%\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparsity in conv1.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.conv1.weight == 0)) / \n",
    "     float(model.conv1.weight.nelement())))\n",
    "print(\"Sparsity in conv2.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.conv2.weight == 0)) /\n",
    "                                                float(model.conv2.weight.nelement())))\n",
    "print(\"Sparsity in fc1.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc1.weight == 0)) / \n",
    "     float(model.fc1.weight.nelement())))\n",
    "print(\"Sparsity in fc2.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc2.weight == 0)) / \n",
    "     float(model.fc2.weight.nelement())))\n",
    "print(\"Sparsity in fc3.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc3.weight == 0)) /\n",
    "                                              float(model.fc3.weight.nelement())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计全局剪枝比例是否和开始设置的值对上了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:47.058474Z",
     "start_time": "2020-05-12T10:49:47.019586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 70.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Global sparsity: {:.2f}%\".format(\n",
    "    100.0 * float(\n",
    "        torch.sum(model.conv1.weight == 0)\n",
    "        + torch.sum(model.conv2.weight == 0)\n",
    "        + torch.sum(model.fc1.weight == 0)\n",
    "        + torch.sum(model.fc2.weight == 0)\n",
    "        + torch.sum(model.fc3.weight == 0)\n",
    "    )\n",
    "    / float(\n",
    "        model.conv1.weight.nelement()\n",
    "        + model.conv2.weight.nelement()\n",
    "        + model.fc1.weight.nelement()\n",
    "        + model.fc2.weight.nelement()\n",
    "        + model.fc3.weight.nelement()\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算0值的个数，结果看来是吻合的，计算结果为14.81%稀疏度，在conv1层的weight上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:47.062309Z",
     "start_time": "2020-05-12T10:49:47.059389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(model.conv1.weight == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:47.068496Z",
     "start_time": "2020-05-12T10:49:47.063127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:47.074746Z",
     "start_time": "2020-05-12T10:49:47.069300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.962962962962962"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 / 54.0 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在保存模型之前，对每个layer运行prune.remove操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:47.091966Z",
     "start_time": "2020-05-12T10:49:47.075711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)) weight\n",
      "Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)) weight\n",
      "Linear(in_features=400, out_features=120, bias=True) weight\n",
      "Linear(in_features=120, out_features=84, bias=True) weight\n",
      "Linear(in_features=84, out_features=10, bias=True) weight\n"
     ]
    }
   ],
   "source": [
    "for module, name in parameters_to_prune:\n",
    "    print(module, name)\n",
    "    prune.remove(module, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们发现weight_orig变成了weight,以及buffers消失了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:47.096386Z",
     "start_time": "2020-05-12T10:49:47.092832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.2426,  0.0405, -0.1719, -0.2918,  0.1032, -0.2013],\n",
       "         requires_grad=True)),\n",
       " ('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0000,  0.2236, -0.1765],\n",
       "            [-0.2056,  0.0000,  0.0956],\n",
       "            [-0.1517, -0.1307,  0.0589]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3187, -0.1342, -0.3088],\n",
       "            [ 0.2113,  0.1509,  0.2444],\n",
       "            [ 0.3229, -0.0791, -0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1260, -0.0882, -0.0923],\n",
       "            [ 0.0000, -0.2917,  0.2162],\n",
       "            [ 0.2980,  0.1482,  0.0661]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0000,  0.0000,  0.2893],\n",
       "            [-0.0928, -0.2500, -0.1400],\n",
       "            [-0.2917, -0.1306, -0.0991]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2521, -0.2847, -0.1455],\n",
       "            [ 0.1204, -0.0744, -0.1320],\n",
       "            [ 0.0618, -0.0815,  0.3171]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0000,  0.2057, -0.1123],\n",
       "            [-0.1371, -0.1937, -0.1119],\n",
       "            [ 0.2638, -0.3006,  0.2665]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:47.100901Z",
     "start_time": "2020-05-12T10:49:47.097379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型以及比较.pth压缩后.zip格式模型的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:47.106892Z",
     "start_time": "2020-05-12T10:49:47.101742Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'sparse_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算下剪枝后模型压缩比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:47.116516Z",
     "start_time": "2020-05-12T10:49:47.107839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6232423490488007"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(241.8 - 91.1) / 241.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:49:47.123526Z",
     "start_time": "2020-05-12T10:49:47.117376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0000,  0.2236, -0.1765],\n",
       "          [-0.2056,  0.0000,  0.0956],\n",
       "          [-0.1517, -0.1307,  0.0589]]],\n",
       "\n",
       "\n",
       "        [[[-0.3187, -0.1342, -0.3088],\n",
       "          [ 0.2113,  0.1509,  0.2444],\n",
       "          [ 0.3229, -0.0791, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1260, -0.0882, -0.0923],\n",
       "          [ 0.0000, -0.2917,  0.2162],\n",
       "          [ 0.2980,  0.1482,  0.0661]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000,  0.2893],\n",
       "          [-0.0928, -0.2500, -0.1400],\n",
       "          [-0.2917, -0.1306, -0.0991]]],\n",
       "\n",
       "\n",
       "        [[[-0.2521, -0.2847, -0.1455],\n",
       "          [ 0.1204, -0.0744, -0.1320],\n",
       "          [ 0.0618, -0.0815,  0.3171]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000,  0.2057, -0.1123],\n",
       "          [-0.1371, -0.1937, -0.1119],\n",
       "          [ 0.2638, -0.3006,  0.2665]]]], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
