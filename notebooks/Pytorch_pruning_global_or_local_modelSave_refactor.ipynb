{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[文章参考来源](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#serializing-a-pruned-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.541873Z",
     "start_time": "2020-05-12T12:14:29.309831Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.547494Z",
     "start_time": "2020-05-12T12:14:29.543005Z"
    }
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)  #输入1通道，输出6通道，kernel_size=3\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        # 全连接层接受的是二维输入，所以要把[batch_size,C,H,W]转化成二维[batch_size,C*H*W]，.nelement()的作用是统计array里元素个数\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 声明一个LeNet网络的实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.557360Z",
     "start_time": "2020-05-12T12:14:29.548534Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.566401Z",
     "start_time": "2020-05-12T12:14:29.558185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.572604Z",
     "start_time": "2020-05-12T12:14:29.567134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测conv1,其中包含了weight和bias,因为还没使用conv1,所以没有buffers产生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.578246Z",
     "start_time": "2020-05-12T12:14:29.573296Z"
    }
   },
   "outputs": [],
   "source": [
    "module = model.conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先说一下后面会用到的几个概念，model.conv1.weight这里的weight是属性，运行prune操作之后产生的稀疏权重会存储在这里，然后我们需要运行prune.remove()操作，才能让model.conv1.weight和model.conv1.named_parameters()的显示结果变成一样\n",
    "\n",
    "model.conv1.named_buffers()运行操作后，生产的mask会在这里\n",
    "\n",
    "model.conv1.named_parameters()模型参数的存储位置，这里面的值会跟随torch.save存储到本地的.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 观察module或者说是conv1,我们发现了weight和bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.586181Z",
     "start_time": "2020-05-12T12:14:29.579533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.2883, -0.2871, -0.1488],\n",
       "            [ 0.1487,  0.1874, -0.3272],\n",
       "            [ 0.1388,  0.2254, -0.1786]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1161,  0.3308,  0.0188],\n",
       "            [ 0.0006, -0.2286,  0.1251],\n",
       "            [-0.2755,  0.2195,  0.1129]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0946,  0.0945,  0.0251],\n",
       "            [-0.1066, -0.0406, -0.2880],\n",
       "            [ 0.1666,  0.0384, -0.2730]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2697, -0.1802,  0.3222],\n",
       "            [ 0.2088, -0.0824, -0.2054],\n",
       "            [-0.3149,  0.3064, -0.2849]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1900, -0.0706, -0.0439],\n",
       "            [-0.2438, -0.0936, -0.3243],\n",
       "            [ 0.1702,  0.2116,  0.1676]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0024,  0.2569, -0.0618],\n",
       "            [-0.0530, -0.2631, -0.2993],\n",
       "            [-0.1027, -0.2437, -0.0877]]]], requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.1581, -0.0478, -0.2425, -0.1367, -0.2110, -0.1112],\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用weight属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.591102Z",
     "start_time": "2020-05-12T12:14:29.587277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.2883, -0.2871, -0.1488],\n",
       "          [ 0.1487,  0.1874, -0.3272],\n",
       "          [ 0.1388,  0.2254, -0.1786]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1161,  0.3308,  0.0188],\n",
       "          [ 0.0006, -0.2286,  0.1251],\n",
       "          [-0.2755,  0.2195,  0.1129]]],\n",
       "\n",
       "\n",
       "        [[[-0.0946,  0.0945,  0.0251],\n",
       "          [-0.1066, -0.0406, -0.2880],\n",
       "          [ 0.1666,  0.0384, -0.2730]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2697, -0.1802,  0.3222],\n",
       "          [ 0.2088, -0.0824, -0.2054],\n",
       "          [-0.3149,  0.3064, -0.2849]]],\n",
       "\n",
       "\n",
       "        [[[-0.1900, -0.0706, -0.0439],\n",
       "          [-0.2438, -0.0936, -0.3243],\n",
       "          [ 0.1702,  0.2116,  0.1676]]],\n",
       "\n",
       "\n",
       "        [[[-0.0024,  0.2569, -0.0618],\n",
       "          [-0.0530, -0.2631, -0.2993],\n",
       "          [-0.1027, -0.2437, -0.0877]]]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 因为还没使用过conv1,所以这里的buffer为空，调用prune之后你会发现差别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.596472Z",
     "start_time": "2020-05-12T12:14:29.591892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对conv1里的weight进行random_unstructured剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.602930Z",
     "start_time": "2020-05-12T12:14:29.597312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.random_unstructured(module, name='weight', amount=0.3) # 裁剪比例设置为0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 你可以发现这里的weight被重命名为weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.611562Z",
     "start_time": "2020-05-12T12:14:29.603858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.1581, -0.0478, -0.2425, -0.1367, -0.2110, -0.1112],\n",
       "         requires_grad=True)),\n",
       " ('weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.2883, -0.2871, -0.1488],\n",
       "            [ 0.1487,  0.1874, -0.3272],\n",
       "            [ 0.1388,  0.2254, -0.1786]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1161,  0.3308,  0.0188],\n",
       "            [ 0.0006, -0.2286,  0.1251],\n",
       "            [-0.2755,  0.2195,  0.1129]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0946,  0.0945,  0.0251],\n",
       "            [-0.1066, -0.0406, -0.2880],\n",
       "            [ 0.1666,  0.0384, -0.2730]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2697, -0.1802,  0.3222],\n",
       "            [ 0.2088, -0.0824, -0.2054],\n",
       "            [-0.3149,  0.3064, -0.2849]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1900, -0.0706, -0.0439],\n",
       "            [-0.2438, -0.0936, -0.3243],\n",
       "            [ 0.1702,  0.2116,  0.1676]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0024,  0.2569, -0.0618],\n",
       "            [-0.0530, -0.2631, -0.2993],\n",
       "            [-0.1027, -0.2437, -0.0877]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.conv1.weight这里的weight是属性，运行prune操作之后产生的稀疏权重会存储在这里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.617024Z",
     "start_time": "2020-05-12T12:14:29.612455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000, -0.0000, -0.1488],\n",
       "          [ 0.1487,  0.1874, -0.3272],\n",
       "          [ 0.0000,  0.0000, -0.1786]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1161,  0.0000,  0.0188],\n",
       "          [ 0.0000, -0.0000,  0.1251],\n",
       "          [-0.2755,  0.0000,  0.1129]]],\n",
       "\n",
       "\n",
       "        [[[-0.0946,  0.0945,  0.0251],\n",
       "          [-0.1066, -0.0406, -0.2880],\n",
       "          [ 0.0000,  0.0384, -0.2730]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2697, -0.1802,  0.3222],\n",
       "          [ 0.0000, -0.0824, -0.2054],\n",
       "          [-0.3149,  0.3064, -0.2849]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000, -0.0439],\n",
       "          [-0.2438, -0.0936, -0.3243],\n",
       "          [ 0.0000,  0.2116,  0.1676]]],\n",
       "\n",
       "\n",
       "        [[[-0.0024,  0.0000, -0.0618],\n",
       "          [-0.0530, -0.0000, -0.2993],\n",
       "          [-0.1027, -0.0000, -0.0877]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight   # 你会发现有些地方的值为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.conv1.named_buffers()运行prune操作后，生成的mask会在这里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.622857Z",
     "start_time": "2020-05-12T12:14:29.617861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight_mask',\n",
       "  tensor([[[[0., 0., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [0., 0., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 1.],\n",
       "            [0., 0., 1.],\n",
       "            [1., 0., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [0., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [0., 1., 1.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [0., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 1.],\n",
       "            [1., 0., 1.],\n",
       "            [1., 0., 1.]]]]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())  # 因为目前只对weight进行了prune，所以只有weight_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行L1_unstructured剪枝操作,不过这里的剪枝对象是conv1里的bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.627973Z",
     "start_time": "2020-05-12T12:14:29.623577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(module, name='bias', amount=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们可以发现bias变成了bias_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.636455Z",
     "start_time": "2020-05-12T12:14:29.628689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.2883, -0.2871, -0.1488],\n",
       "            [ 0.1487,  0.1874, -0.3272],\n",
       "            [ 0.1388,  0.2254, -0.1786]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.1161,  0.3308,  0.0188],\n",
       "            [ 0.0006, -0.2286,  0.1251],\n",
       "            [-0.2755,  0.2195,  0.1129]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0946,  0.0945,  0.0251],\n",
       "            [-0.1066, -0.0406, -0.2880],\n",
       "            [ 0.1666,  0.0384, -0.2730]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2697, -0.1802,  0.3222],\n",
       "            [ 0.2088, -0.0824, -0.2054],\n",
       "            [-0.3149,  0.3064, -0.2849]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1900, -0.0706, -0.0439],\n",
       "            [-0.2438, -0.0936, -0.3243],\n",
       "            [ 0.1702,  0.2116,  0.1676]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0024,  0.2569, -0.0618],\n",
       "            [-0.0530, -0.2631, -0.2993],\n",
       "            [-0.1027, -0.2437, -0.0877]]]], requires_grad=True)),\n",
       " ('bias_orig',\n",
       "  Parameter containing:\n",
       "  tensor([-0.1581, -0.0478, -0.2425, -0.1367, -0.2110, -0.1112],\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生了bias_mask，这样子的话conv1里的weight和bias都进行了剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.642161Z",
     "start_time": "2020-05-12T12:14:29.637533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight_mask',\n",
       "  tensor([[[[0., 0., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [0., 0., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 1.],\n",
       "            [0., 0., 1.],\n",
       "            [1., 0., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [0., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [0., 1., 1.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [0., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 1.],\n",
       "            [1., 0., 1.],\n",
       "            [1., 0., 1.]]]])),\n",
       " ('bias_mask', tensor([1., 0., 1., 1., 1., 0.]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行ln_structured剪枝，注意看输出的weight,都是一整个channel为0的，剪枝的话，是可以连续剪枝的，这里是第二次对conv1里的weight进行剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.646850Z",
     "start_time": "2020-05-12T12:14:29.643459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.ln_structured(module, name='weight', amount=0.5, n=2, dim=0)\n",
    "# as we can verify, this will zero out all the connections corresponding to 50%(3 out of 6) of the channels,\n",
    "# while preserving the action of the previous mask\n",
    "# removing the specified amount of (currently unpruned) channels along the specified dim with the lowest L``n``-norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the forward pass to work without modification, the weight attribute needs to exist. The pruning techniques implemented in torch.nn.utils.prune compute the pruned version of the weight(by combining the mask with the original parameter) and store them in the attribute weight. Note, this is no longer a parameter of the module, it is now simply an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.652720Z",
     "start_time": "2020-05-12T12:14:29.647929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000, -0.0000, -0.1488],\n",
       "          [ 0.1487,  0.1874, -0.3272],\n",
       "          [ 0.0000,  0.0000, -0.1786]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2697, -0.1802,  0.3222],\n",
       "          [ 0.0000, -0.0824, -0.2054],\n",
       "          [-0.3149,  0.3064, -0.2849]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000, -0.0000, -0.0439],\n",
       "          [-0.2438, -0.0936, -0.3243],\n",
       "          [ 0.0000,  0.2116,  0.1676]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000, -0.0000]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.657995Z",
     "start_time": "2020-05-12T12:14:29.653506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prune.remove之后，我们发现weight_orig变成了weight, 其实就是把module.weight的值赋值给了weight_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行prune.remove的作用，to make the pruning permanent, remove the re-parametrization in terms of weight_orig and weight_mask, and remove the forward_pre_hook, we can use the remove functionality from torch.nn.utils.prune. Note that this doesn't undo the pruning, as if it never happened. it simply makes it permanent, instead, by reassigning the parameter weight to the model parameters, in its pruned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.664180Z",
     "start_time": "2020-05-12T12:14:29.658840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.remove(module, 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们发现weight_orig变成了weight，而且数值也发生了变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.670957Z",
     "start_time": "2020-05-12T12:14:29.665072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias_orig',\n",
       "  Parameter containing:\n",
       "  tensor([-0.1581, -0.0478, -0.2425, -0.1367, -0.2110, -0.1112],\n",
       "         requires_grad=True)),\n",
       " ('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0000, -0.0000, -0.1488],\n",
       "            [ 0.1487,  0.1874, -0.3272],\n",
       "            [ 0.0000,  0.0000, -0.1786]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000, -0.0000,  0.0000],\n",
       "            [-0.0000,  0.0000,  0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0000,  0.0000,  0.0000],\n",
       "            [-0.0000, -0.0000, -0.0000],\n",
       "            [ 0.0000,  0.0000, -0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2697, -0.1802,  0.3222],\n",
       "            [ 0.0000, -0.0824, -0.2054],\n",
       "            [-0.3149,  0.3064, -0.2849]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0000, -0.0000, -0.0439],\n",
       "            [-0.2438, -0.0936, -0.3243],\n",
       "            [ 0.0000,  0.2116,  0.1676]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0000,  0.0000, -0.0000],\n",
       "            [-0.0000, -0.0000, -0.0000],\n",
       "            [-0.0000, -0.0000, -0.0000]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## buffers里的weight_mask不在了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.676004Z",
     "start_time": "2020-05-12T12:14:29.672494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias_mask', tensor([1., 0., 1., 1., 1., 0.]))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prunning multiple parameters in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.681316Z",
     "start_time": "2020-05-12T12:14:29.676945Z"
    }
   },
   "outputs": [],
   "source": [
    "new_model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.730453Z",
     "start_time": "2020-05-12T12:14:29.683045Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, module in new_model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.2)\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.733752Z",
     "start_time": "2020-05-12T12:14:29.731331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(new_model.named_buffers()).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so far, we only looked at what is usually referred to as \"local\" pruning, the practice of pruning tensors in a model one by one, by comparing the statisitcs(weight magnitude, activation, gradient) of each entry exclusively to the other entries in that tensor. however, a common and perhaps more powerful technique is to prune the model all at once, by removing(for example) the lowest 20% of connections across the whole model, instead of removing the lowest 20% of connections in each layer. this is likely to result in different pruning percentages per layer. let's ses how to do that using global_unstructured from torch.nn.utils.prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.739716Z",
     "start_time": "2020-05-12T12:14:29.734554Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设定要剪枝的对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.745200Z",
     "start_time": "2020-05-12T12:14:29.742792Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    "    (model.fc3, 'weight')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.836077Z",
     "start_time": "2020-05-12T12:14:29.746061Z"
    }
   },
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看每层剪枝比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.866182Z",
     "start_time": "2020-05-12T12:14:29.837171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1.weight: 9.26%\n",
      "Sparsity in conv2.weight: 29.75%\n",
      "Sparsity in fc1.weight: 77.21%\n",
      "Sparsity in fc2.weight: 42.58%\n",
      "Sparsity in fc3.weight: 32.62%\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparsity in conv1.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.conv1.weight == 0)) / \n",
    "     float(model.conv1.weight.nelement())))\n",
    "print(\"Sparsity in conv2.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.conv2.weight == 0)) /\n",
    "                                                float(model.conv2.weight.nelement())))\n",
    "print(\"Sparsity in fc1.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc1.weight == 0)) / \n",
    "     float(model.fc1.weight.nelement())))\n",
    "print(\"Sparsity in fc2.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc2.weight == 0)) / \n",
    "     float(model.fc2.weight.nelement())))\n",
    "print(\"Sparsity in fc3.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc3.weight == 0)) /\n",
    "                                              float(model.fc3.weight.nelement())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计全局剪枝比例是否和开始设置的值对上了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.880073Z",
     "start_time": "2020-05-12T12:14:29.866988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 70.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Global sparsity: {:.2f}%\".format(\n",
    "    100.0 * float(\n",
    "        torch.sum(model.conv1.weight == 0)\n",
    "        + torch.sum(model.conv2.weight == 0)\n",
    "        + torch.sum(model.fc1.weight == 0)\n",
    "        + torch.sum(model.fc2.weight == 0)\n",
    "        + torch.sum(model.fc3.weight == 0)\n",
    "    )\n",
    "    / float(\n",
    "        model.conv1.weight.nelement()\n",
    "        + model.conv2.weight.nelement()\n",
    "        + model.fc1.weight.nelement()\n",
    "        + model.fc2.weight.nelement()\n",
    "        + model.fc3.weight.nelement()\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算0值的个数，结果看来是吻合的，计算结果为12.96%稀疏度，在conv1层的weight上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.883522Z",
     "start_time": "2020-05-12T12:14:29.880842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(model.conv1.weight == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.889677Z",
     "start_time": "2020-05-12T12:14:29.886074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.894986Z",
     "start_time": "2020-05-12T12:14:29.890593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.962962962962962"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 / 54.0 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在保存模型之前，对每个layer运行prune.remove操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.910706Z",
     "start_time": "2020-05-12T12:14:29.895833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)) weight\n",
      "Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)) weight\n",
      "Linear(in_features=400, out_features=120, bias=True) weight\n",
      "Linear(in_features=120, out_features=84, bias=True) weight\n",
      "Linear(in_features=84, out_features=10, bias=True) weight\n"
     ]
    }
   ],
   "source": [
    "for module, name in parameters_to_prune:\n",
    "    print(module, name)\n",
    "    prune.remove(module, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们发现weight_orig变成了weight,以及buffers消失了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.918264Z",
     "start_time": "2020-05-12T12:14:29.913332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.2758, -0.1346, -0.0783,  0.2933, -0.0245, -0.0623],\n",
       "         requires_grad=True)),\n",
       " ('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.1302, -0.0000,  0.1887],\n",
       "            [ 0.2554,  0.0000,  0.2567],\n",
       "            [ 0.2766, -0.1629,  0.1217]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0000,  0.1007,  0.1686],\n",
       "            [ 0.1041,  0.2123,  0.3197],\n",
       "            [ 0.2913, -0.0429,  0.0953]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2861,  0.2952, -0.1976],\n",
       "            [-0.0772, -0.2643,  0.3295],\n",
       "            [-0.1173,  0.1237, -0.3206]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1447,  0.0538, -0.1000],\n",
       "            [-0.2208, -0.1044,  0.0000],\n",
       "            [ 0.2880, -0.3208, -0.2418]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2555, -0.1344,  0.3084],\n",
       "            [-0.1633,  0.2444,  0.2716],\n",
       "            [ 0.2163,  0.2251, -0.3108]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0000, -0.1329,  0.1795],\n",
       "            [-0.2698, -0.0423, -0.1835],\n",
       "            [ 0.1210,  0.1618,  0.3296]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.922097Z",
     "start_time": "2020-05-12T12:14:29.919266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型以及比较.pth压缩后.zip格式模型的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.928491Z",
     "start_time": "2020-05-12T12:14:29.922887Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'sparse_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算下剪枝后模型压缩比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.934979Z",
     "start_time": "2020-05-12T12:14:29.929308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6232423490488007"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(241.8 - 91.1) / 241.8  # 前者为压缩前，后者为压缩后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:14:29.941923Z",
     "start_time": "2020-05-12T12:14:29.935726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.1302, -0.0000,  0.1887],\n",
       "          [ 0.2554,  0.0000,  0.2567],\n",
       "          [ 0.2766, -0.1629,  0.1217]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.1007,  0.1686],\n",
       "          [ 0.1041,  0.2123,  0.3197],\n",
       "          [ 0.2913, -0.0429,  0.0953]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2861,  0.2952, -0.1976],\n",
       "          [-0.0772, -0.2643,  0.3295],\n",
       "          [-0.1173,  0.1237, -0.3206]]],\n",
       "\n",
       "\n",
       "        [[[-0.1447,  0.0538, -0.1000],\n",
       "          [-0.2208, -0.1044,  0.0000],\n",
       "          [ 0.2880, -0.3208, -0.2418]]],\n",
       "\n",
       "\n",
       "        [[[-0.2555, -0.1344,  0.3084],\n",
       "          [-0.1633,  0.2444,  0.2716],\n",
       "          [ 0.2163,  0.2251, -0.3108]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -0.1329,  0.1795],\n",
       "          [-0.2698, -0.0423, -0.1835],\n",
       "          [ 0.1210,  0.1618,  0.3296]]]], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
