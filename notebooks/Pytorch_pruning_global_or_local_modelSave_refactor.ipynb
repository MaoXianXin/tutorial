{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[文章参考来源](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#serializing-a-pruned-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.497248Z",
     "start_time": "2020-05-13T09:26:55.273404Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.502875Z",
     "start_time": "2020-05-13T09:26:55.498325Z"
    }
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)  #输入1通道，输出6通道，kernel_size=3\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10) # 因为是10分类，所以最后一层的神经元个数为10\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        # 全连接层接受的是二维输入，所以要把[batch_size,C,H,W]转化成二维[batch_size,C*H*W]，.nelement()的作用是统计array里元素个数\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) # 返回logits\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 声明一个LeNet网络的实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.518346Z",
     "start_time": "2020-05-13T09:26:55.503882Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.531604Z",
     "start_time": "2020-05-13T09:26:55.520535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.538408Z",
     "start_time": "2020-05-13T09:26:55.532869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测conv1,其中包含了weight和bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.543664Z",
     "start_time": "2020-05-13T09:26:55.539428Z"
    }
   },
   "outputs": [],
   "source": [
    "module = model.conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先说一下后面会用到的几个概念，model.conv1.weight这里的weight是属性，运行prune操作之后产生的稀疏权重会存储在这里，然后我们需要运行prune.remove()操作，才能让model.conv1.weight和model.conv1.named_parameters()的显示结果变成一样\n",
    "\n",
    "model.conv1.named_buffers()运行操作后，生成的mask会在这里\n",
    "\n",
    "model.conv1.named_parameters()模型参数的存储位置，这里面的值会跟随torch.save存储到本地的.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 观察module或者说是conv1,我们发现了weight和bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.551681Z",
     "start_time": "2020-05-13T09:26:55.545296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0436,  0.2702,  0.0559],\n",
       "            [ 0.1413, -0.0787, -0.1531],\n",
       "            [ 0.0558,  0.2458, -0.0896]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2921,  0.1019,  0.0539],\n",
       "            [ 0.1019,  0.2754, -0.1386],\n",
       "            [-0.2756, -0.1292,  0.1475]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2188,  0.0133, -0.1130],\n",
       "            [-0.1287,  0.2355, -0.1248],\n",
       "            [ 0.2215,  0.1693,  0.0800]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1820, -0.0322,  0.1641],\n",
       "            [-0.1137, -0.1801, -0.1784],\n",
       "            [-0.2672,  0.3220, -0.2941]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3005,  0.1728,  0.1805],\n",
       "            [ 0.0071,  0.1560, -0.0921],\n",
       "            [ 0.0193, -0.2779,  0.0085]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0596,  0.2006, -0.0119],\n",
       "            [ 0.2035, -0.0278,  0.2438],\n",
       "            [-0.3046, -0.1751,  0.2437]]]], requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0568, -0.0444,  0.1789,  0.2256,  0.0646, -0.1924],\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用weight属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.556683Z",
     "start_time": "2020-05-13T09:26:55.552925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0436,  0.2702,  0.0559],\n",
       "          [ 0.1413, -0.0787, -0.1531],\n",
       "          [ 0.0558,  0.2458, -0.0896]]],\n",
       "\n",
       "\n",
       "        [[[-0.2921,  0.1019,  0.0539],\n",
       "          [ 0.1019,  0.2754, -0.1386],\n",
       "          [-0.2756, -0.1292,  0.1475]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2188,  0.0133, -0.1130],\n",
       "          [-0.1287,  0.2355, -0.1248],\n",
       "          [ 0.2215,  0.1693,  0.0800]]],\n",
       "\n",
       "\n",
       "        [[[-0.1820, -0.0322,  0.1641],\n",
       "          [-0.1137, -0.1801, -0.1784],\n",
       "          [-0.2672,  0.3220, -0.2941]]],\n",
       "\n",
       "\n",
       "        [[[-0.3005,  0.1728,  0.1805],\n",
       "          [ 0.0071,  0.1560, -0.0921],\n",
       "          [ 0.0193, -0.2779,  0.0085]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0596,  0.2006, -0.0119],\n",
       "          [ 0.2035, -0.0278,  0.2438],\n",
       "          [-0.3046, -0.1751,  0.2437]]]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 因为还没使用过conv1,所以这里的buffer为空，调用prune之后你会发现差别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.561636Z",
     "start_time": "2020-05-13T09:26:55.557460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对conv1里的weight进行random_unstructured剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.568338Z",
     "start_time": "2020-05-13T09:26:55.562413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.random_unstructured(module, name='weight', amount=0.3) # 裁剪比例设置为0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 你可以发现这里的weight被重命名为weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.576929Z",
     "start_time": "2020-05-13T09:26:55.569140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0568, -0.0444,  0.1789,  0.2256,  0.0646, -0.1924],\n",
       "         requires_grad=True)),\n",
       " ('weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0436,  0.2702,  0.0559],\n",
       "            [ 0.1413, -0.0787, -0.1531],\n",
       "            [ 0.0558,  0.2458, -0.0896]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2921,  0.1019,  0.0539],\n",
       "            [ 0.1019,  0.2754, -0.1386],\n",
       "            [-0.2756, -0.1292,  0.1475]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2188,  0.0133, -0.1130],\n",
       "            [-0.1287,  0.2355, -0.1248],\n",
       "            [ 0.2215,  0.1693,  0.0800]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1820, -0.0322,  0.1641],\n",
       "            [-0.1137, -0.1801, -0.1784],\n",
       "            [-0.2672,  0.3220, -0.2941]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3005,  0.1728,  0.1805],\n",
       "            [ 0.0071,  0.1560, -0.0921],\n",
       "            [ 0.0193, -0.2779,  0.0085]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0596,  0.2006, -0.0119],\n",
       "            [ 0.2035, -0.0278,  0.2438],\n",
       "            [-0.3046, -0.1751,  0.2437]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.conv1.weight这里的weight是属性，运行prune操作之后产生的稀疏权重会存储在这里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.582329Z",
     "start_time": "2020-05-13T09:26:55.578316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0436,  0.0000,  0.0559],\n",
       "          [ 0.1413, -0.0787, -0.1531],\n",
       "          [ 0.0558,  0.0000, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000,  0.1019,  0.0000],\n",
       "          [ 0.1019,  0.2754, -0.1386],\n",
       "          [-0.2756, -0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0133, -0.1130],\n",
       "          [-0.1287,  0.2355, -0.1248],\n",
       "          [ 0.2215,  0.1693,  0.0800]]],\n",
       "\n",
       "\n",
       "        [[[-0.1820, -0.0000,  0.1641],\n",
       "          [-0.1137, -0.1801, -0.1784],\n",
       "          [-0.2672,  0.3220, -0.2941]]],\n",
       "\n",
       "\n",
       "        [[[-0.3005,  0.1728,  0.1805],\n",
       "          [ 0.0071,  0.0000, -0.0921],\n",
       "          [ 0.0000, -0.2779,  0.0085]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000, -0.0000],\n",
       "          [ 0.2035, -0.0278,  0.2438],\n",
       "          [-0.0000, -0.0000,  0.2437]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight   # 你会发现有些地方的值为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.conv1.named_buffers()运行prune操作后，生成的mask会在这里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.588043Z",
     "start_time": "2020-05-13T09:26:55.583496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight_mask',\n",
       "  tensor([[[[1., 0., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 1., 0.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 1., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [1., 0., 1.],\n",
       "            [0., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.],\n",
       "            [1., 1., 1.],\n",
       "            [0., 0., 1.]]]]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())  # 因为目前只对weight进行了prune，所以只有weight_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行L1_unstructured剪枝操作,不过这里的剪枝对象是conv1里的bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.593140Z",
     "start_time": "2020-05-13T09:26:55.588909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(module, name='bias', amount=0.3) # 裁剪比例设置为0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们可以发现bias变成了bias_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.600183Z",
     "start_time": "2020-05-13T09:26:55.593870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0436,  0.2702,  0.0559],\n",
       "            [ 0.1413, -0.0787, -0.1531],\n",
       "            [ 0.0558,  0.2458, -0.0896]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2921,  0.1019,  0.0539],\n",
       "            [ 0.1019,  0.2754, -0.1386],\n",
       "            [-0.2756, -0.1292,  0.1475]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2188,  0.0133, -0.1130],\n",
       "            [-0.1287,  0.2355, -0.1248],\n",
       "            [ 0.2215,  0.1693,  0.0800]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1820, -0.0322,  0.1641],\n",
       "            [-0.1137, -0.1801, -0.1784],\n",
       "            [-0.2672,  0.3220, -0.2941]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3005,  0.1728,  0.1805],\n",
       "            [ 0.0071,  0.1560, -0.0921],\n",
       "            [ 0.0193, -0.2779,  0.0085]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0596,  0.2006, -0.0119],\n",
       "            [ 0.2035, -0.0278,  0.2438],\n",
       "            [-0.3046, -0.1751,  0.2437]]]], requires_grad=True)),\n",
       " ('bias_orig',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0568, -0.0444,  0.1789,  0.2256,  0.0646, -0.1924],\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生了bias_mask，这样子的话conv1里的weight和bias都进行了剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.607669Z",
     "start_time": "2020-05-13T09:26:55.601138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight_mask',\n",
       "  tensor([[[[1., 0., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 1., 0.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 1., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 0., 1.],\n",
       "            [1., 1., 1.],\n",
       "            [1., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[1., 1., 1.],\n",
       "            [1., 0., 1.],\n",
       "            [0., 1., 1.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.],\n",
       "            [1., 1., 1.],\n",
       "            [0., 0., 1.]]]])),\n",
       " ('bias_mask', tensor([0., 0., 1., 1., 1., 1.]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行ln_structured剪枝，注意看输出的weight,都是一整个channel为0的，剪枝的话，是可以连续剪枝的，这里是第二次对conv1里的weight进行剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.613104Z",
     "start_time": "2020-05-13T09:26:55.608940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.ln_structured(module, name='weight', amount=0.5, n=2, dim=0)\n",
    "# as we can verify, this will zero out all the connections corresponding to 50%(3 out of 6) of the channels,\n",
    "# while preserving the action of the previous mask\n",
    "# removing the specified amount of (currently unpruned) channels along the specified dim with the lowest L``n``-norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the forward pass to work without modification, the weight attribute needs to exist. The pruning techniques implemented in torch.nn.utils.prune compute the pruned version of the weight(by combining the mask with the original parameter) and store them in the attribute weight. Note, this is no longer a parameter of the module, it is now simply an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.618311Z",
     "start_time": "2020-05-13T09:26:55.613895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0000,  0.1019,  0.0000],\n",
       "          [ 0.1019,  0.2754, -0.1386],\n",
       "          [-0.2756, -0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000, -0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.1820, -0.0000,  0.1641],\n",
       "          [-0.1137, -0.1801, -0.1784],\n",
       "          [-0.2672,  0.3220, -0.2941]]],\n",
       "\n",
       "\n",
       "        [[[-0.3005,  0.1728,  0.1805],\n",
       "          [ 0.0071,  0.0000, -0.0921],\n",
       "          [ 0.0000, -0.2779,  0.0085]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000,  0.0000]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.623740Z",
     "start_time": "2020-05-13T09:26:55.619130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prune.remove之后，我们发现weight_orig变成了weight, 其实就是把module.weight的值赋值给了weight_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行prune.remove的作用，to make the pruning permanent, remove the re-parametrization in terms of weight_orig and weight_mask, and remove the forward_pre_hook, we can use the remove functionality from torch.nn.utils.prune. Note that this doesn't undo the pruning, as if it never happened. it simply makes it permanent, instead, by reassigning the parameter weight to the model parameters, in its pruned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.633382Z",
     "start_time": "2020-05-13T09:26:55.624519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.remove(module, 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们发现weight_orig变成了weight，而且数值也发生了变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.640966Z",
     "start_time": "2020-05-13T09:26:55.634168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias_orig',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0568, -0.0444,  0.1789,  0.2256,  0.0646, -0.1924],\n",
       "         requires_grad=True)),\n",
       " ('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0000,  0.0000,  0.0000],\n",
       "            [ 0.0000, -0.0000, -0.0000],\n",
       "            [ 0.0000,  0.0000, -0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0000,  0.1019,  0.0000],\n",
       "            [ 0.1019,  0.2754, -0.1386],\n",
       "            [-0.2756, -0.0000,  0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0000,  0.0000, -0.0000],\n",
       "            [-0.0000,  0.0000, -0.0000],\n",
       "            [ 0.0000,  0.0000,  0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1820, -0.0000,  0.1641],\n",
       "            [-0.1137, -0.1801, -0.1784],\n",
       "            [-0.2672,  0.3220, -0.2941]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3005,  0.1728,  0.1805],\n",
       "            [ 0.0071,  0.0000, -0.0921],\n",
       "            [ 0.0000, -0.2779,  0.0085]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0000,  0.0000, -0.0000],\n",
       "            [ 0.0000, -0.0000,  0.0000],\n",
       "            [-0.0000, -0.0000,  0.0000]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## buffers里的weight_mask不在了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.646333Z",
     "start_time": "2020-05-13T09:26:55.642553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias_mask', tensor([0., 0., 1., 1., 1., 1.]))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prunning multiple parameters in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.652017Z",
     "start_time": "2020-05-13T09:26:55.647288Z"
    }
   },
   "outputs": [],
   "source": [
    "new_model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.734437Z",
     "start_time": "2020-05-13T09:26:55.652861Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, module in new_model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d): # 收集卷积模块\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.2) # 只对weight剪枝，比例为0.2\n",
    "    elif isinstance(module, torch.nn.Linear): # 收集全连接模块\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.4) # 只对weight剪枝，比例为0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.747028Z",
     "start_time": "2020-05-13T09:26:55.744141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(new_model.named_buffers()).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so far, we only looked at what is usually referred to as \"local\" pruning, the practice of pruning tensors in a model one by one, by comparing the statisitcs(weight magnitude, activation, gradient) of each entry exclusively to the other entries in that tensor. however, a common and perhaps more powerful technique is to prune the model all at once, by removing(for example) the lowest 20% of connections across the whole model, instead of removing the lowest 20% of connections in each layer. this is likely to result in different pruning percentages per layer. let's ses how to do that using global_unstructured from torch.nn.utils.prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.757225Z",
     "start_time": "2020-05-13T09:26:55.747964Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设定要剪枝的对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.762571Z",
     "start_time": "2020-05-13T09:26:55.757977Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    "    (model.fc3, 'weight')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.991702Z",
     "start_time": "2020-05-13T09:26:55.763319Z"
    }
   },
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,  # 接受元组形式\n",
    "    pruning_method=prune.L1Unstructured, # L1非结构化剪枝\n",
    "    amount=0.7 # 裁剪比例设置为0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看每层剪枝比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:55.999670Z",
     "start_time": "2020-05-13T09:26:55.992474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1.weight: 12.96%\n",
      "Sparsity in conv2.weight: 26.97%\n",
      "Sparsity in fc1.weight: 77.06%\n",
      "Sparsity in fc2.weight: 43.20%\n",
      "Sparsity in fc3.weight: 36.19%\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparsity in conv1.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.conv1.weight == 0)) / \n",
    "     float(model.conv1.weight.nelement())))\n",
    "print(\"Sparsity in conv2.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.conv2.weight == 0)) /\n",
    "                                                float(model.conv2.weight.nelement())))\n",
    "print(\"Sparsity in fc1.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc1.weight == 0)) / \n",
    "     float(model.fc1.weight.nelement())))\n",
    "print(\"Sparsity in fc2.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc2.weight == 0)) / \n",
    "     float(model.fc2.weight.nelement())))\n",
    "print(\"Sparsity in fc3.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc3.weight == 0)) /\n",
    "                                              float(model.fc3.weight.nelement())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计全局剪枝比例是否和开始设置的值对上了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:56.012203Z",
     "start_time": "2020-05-13T09:26:56.000595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 70.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Global sparsity: {:.2f}%\".format(\n",
    "    100.0 * float(\n",
    "        torch.sum(model.conv1.weight == 0)\n",
    "        + torch.sum(model.conv2.weight == 0)\n",
    "        + torch.sum(model.fc1.weight == 0)\n",
    "        + torch.sum(model.fc2.weight == 0)\n",
    "        + torch.sum(model.fc3.weight == 0)\n",
    "    )\n",
    "    / float(\n",
    "        model.conv1.weight.nelement()\n",
    "        + model.conv2.weight.nelement()\n",
    "        + model.fc1.weight.nelement()\n",
    "        + model.fc2.weight.nelement()\n",
    "        + model.fc3.weight.nelement()\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算0值的个数，结果看来是吻合的，计算结果为12.96%稀疏度，在conv1层的weight上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:56.015319Z",
     "start_time": "2020-05-13T09:26:56.012939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(model.conv1.weight == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:56.022155Z",
     "start_time": "2020-05-13T09:26:56.016089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:56.030298Z",
     "start_time": "2020-05-13T09:26:56.025288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.962962962962962"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 / 54.0 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在保存模型之前，对每个layer运行prune.remove操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:56.043273Z",
     "start_time": "2020-05-13T09:26:56.031174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)) weight\n",
      "Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)) weight\n",
      "Linear(in_features=400, out_features=120, bias=True) weight\n",
      "Linear(in_features=120, out_features=84, bias=True) weight\n",
      "Linear(in_features=84, out_features=10, bias=True) weight\n"
     ]
    }
   ],
   "source": [
    "for module, name in parameters_to_prune:\n",
    "    print(module, name)\n",
    "    prune.remove(module, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们发现weight_orig变成了weight,以及buffers消失了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:56.047687Z",
     "start_time": "2020-05-13T09:26:56.044210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.2713, -0.2962,  0.1615, -0.0092,  0.0532,  0.2505],\n",
       "         requires_grad=True)),\n",
       " ('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-0.2913, -0.0000, -0.0000],\n",
       "            [-0.2775, -0.0000, -0.2242],\n",
       "            [ 0.2880,  0.1896,  0.0476]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2580,  0.2894, -0.2938],\n",
       "            [ 0.0835,  0.0000,  0.1750],\n",
       "            [ 0.1294,  0.1813, -0.2590]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3096,  0.2377, -0.3243],\n",
       "            [ 0.2653,  0.2832, -0.0856],\n",
       "            [-0.0602,  0.2314,  0.1457]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0613, -0.2724, -0.0000],\n",
       "            [ 0.0730, -0.1033, -0.1826],\n",
       "            [-0.2681,  0.2517, -0.0915]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2669, -0.1155, -0.0000],\n",
       "            [-0.1073, -0.3000,  0.2573],\n",
       "            [ 0.0000, -0.0541, -0.0402]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2933,  0.3057, -0.1105],\n",
       "            [ 0.2823,  0.1902, -0.1146],\n",
       "            [ 0.0639,  0.2808, -0.2625]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:56.052112Z",
     "start_time": "2020-05-13T09:26:56.048641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型以及比较.pth压缩后.zip格式模型的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:56.058195Z",
     "start_time": "2020-05-13T09:26:56.052862Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'sparse_model.pth') #这种方式只保存权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算下剪枝后模型压缩比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:56.069456Z",
     "start_time": "2020-05-13T09:26:56.059064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6232423490488007"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(241.8 - 91.1) / 241.8  # 前者为压缩前，后者为压缩后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:26:56.076681Z",
     "start_time": "2020-05-13T09:26:56.070544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.2913, -0.0000, -0.0000],\n",
       "          [-0.2775, -0.0000, -0.2242],\n",
       "          [ 0.2880,  0.1896,  0.0476]]],\n",
       "\n",
       "\n",
       "        [[[-0.2580,  0.2894, -0.2938],\n",
       "          [ 0.0835,  0.0000,  0.1750],\n",
       "          [ 0.1294,  0.1813, -0.2590]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3096,  0.2377, -0.3243],\n",
       "          [ 0.2653,  0.2832, -0.0856],\n",
       "          [-0.0602,  0.2314,  0.1457]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0613, -0.2724, -0.0000],\n",
       "          [ 0.0730, -0.1033, -0.1826],\n",
       "          [-0.2681,  0.2517, -0.0915]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2669, -0.1155, -0.0000],\n",
       "          [-0.1073, -0.3000,  0.2573],\n",
       "          [ 0.0000, -0.0541, -0.0402]]],\n",
       "\n",
       "\n",
       "        [[[-0.2933,  0.3057, -0.1105],\n",
       "          [ 0.2823,  0.1902, -0.1146],\n",
       "          [ 0.0639,  0.2808, -0.2625]]]], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
