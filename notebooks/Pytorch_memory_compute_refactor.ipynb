{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入函数库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:05.488671Z",
     "start_time": "2020-05-13T06:01:05.117307Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载在ImageNet上预训练过的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.286624Z",
     "start_time": "2020-05-13T06:01:05.489654Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看模型的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.293416Z",
     "start_time": "2020-05-13T06:01:06.287567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看模型的卷积层和全连接层的参数shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.308152Z",
     "start_time": "2020-05-13T06:01:06.294383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([4096, 25088])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([1000, 4096])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数个数统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.314516Z",
     "start_time": "2020-05-13T06:01:06.309010Z"
    }
   },
   "outputs": [],
   "source": [
    "para = sum([np.prod(list(p.size())) for p in model.parameters()])  # np.prod([3, 4, 5]) = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算参数大小，因为存储的是FP32，相当于4个字节"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们换算成熟悉的Mb表示，我们可以发现这个和实际下载过来的vgg16.pth的模型大小是一致的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.322343Z",
     "start_time": "2020-05-13T06:01:06.315467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527.7921447753906"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para * 4 / 1024 / 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算模型forward和backward过程中，产生的output feature map的大小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模拟输入，注意输入的shape要和预训练模型的输入shape一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.342374Z",
     "start_time": "2020-05-13T06:01:06.324115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.ones([1, 3, 224, 224], dtype=torch.float32)\n",
    "input_ = input.clone()\n",
    "input_.requires_grad_(requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把模型里的模块转换成列表形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.345532Z",
     "start_time": "2020-05-13T06:01:06.343461Z"
    }
   },
   "outputs": [],
   "source": [
    "mods = list(model.modules())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 收集输出的output feature map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意这里要分2段来计算，我们可以输出mods来观察一下,可以发现有些模块不是我们想要的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.352685Z",
     "start_time": "2020-05-13T06:01:06.346358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VGG(\n",
       "   (features): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (3): ReLU(inplace=True)\n",
       "     (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (6): ReLU(inplace=True)\n",
       "     (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (8): ReLU(inplace=True)\n",
       "     (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (11): ReLU(inplace=True)\n",
       "     (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (13): ReLU(inplace=True)\n",
       "     (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (15): ReLU(inplace=True)\n",
       "     (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (18): ReLU(inplace=True)\n",
       "     (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (20): ReLU(inplace=True)\n",
       "     (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (22): ReLU(inplace=True)\n",
       "     (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (25): ReLU(inplace=True)\n",
       "     (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (27): ReLU(inplace=True)\n",
       "     (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (29): ReLU(inplace=True)\n",
       "     (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "   (classifier): Sequential(\n",
       "     (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Dropout(p=0.5, inplace=False)\n",
       "     (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "     (4): ReLU(inplace=True)\n",
       "     (5): Dropout(p=0.5, inplace=False)\n",
       "     (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (3): ReLU(inplace=True)\n",
       "   (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (6): ReLU(inplace=True)\n",
       "   (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (8): ReLU(inplace=True)\n",
       "   (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (11): ReLU(inplace=True)\n",
       "   (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (13): ReLU(inplace=True)\n",
       "   (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (15): ReLU(inplace=True)\n",
       "   (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (18): ReLU(inplace=True)\n",
       "   (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (20): ReLU(inplace=True)\n",
       "   (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (22): ReLU(inplace=True)\n",
       "   (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (25): ReLU(inplace=True)\n",
       "   (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (27): ReLU(inplace=True)\n",
       "   (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (29): ReLU(inplace=True)\n",
       "   (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " AdaptiveAvgPool2d(output_size=(7, 7)),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Dropout(p=0.5, inplace=False)\n",
       "   (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "   (4): ReLU(inplace=True)\n",
       "   (5): Dropout(p=0.5, inplace=False)\n",
       "   (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       " ),\n",
       " Linear(in_features=25088, out_features=4096, bias=True),\n",
       " ReLU(inplace=True),\n",
       " Dropout(p=0.5, inplace=False),\n",
       " Linear(in_features=4096, out_features=4096, bias=True),\n",
       " ReLU(inplace=True),\n",
       " Dropout(p=0.5, inplace=False),\n",
       " Linear(in_features=4096, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.358454Z",
     "start_time": "2020-05-13T06:01:06.353498Z"
    }
   },
   "outputs": [],
   "source": [
    "out_sizes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一段模块输出收集,这个是卷积模块,输出shape=[batch_size,C,H,W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.539505Z",
     "start_time": "2020-05-13T06:01:06.359263Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(2, 34):\n",
    "    m = mods[i]\n",
    "    if isinstance(m, nn.ReLU):\n",
    "        # inplace=True means that it will modify the input directly, without allocating any additional\n",
    "        # output. It can sometimes slightly decrease the memory usage, but may not always be a valid\n",
    "        # operation(because the original input is destroyed). if you don't see an error, it means that\n",
    "        # your use case is valid\n",
    "        if m.inplace:\n",
    "            continue\n",
    "    out = m(input_)\n",
    "    out_sizes.append(np.array(out.size()))\n",
    "    input_ = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.545039Z",
     "start_time": "2020-05-13T06:01:06.541433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 7, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积层的输出要转化成二维的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.552095Z",
     "start_time": "2020-05-13T06:01:06.545873Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ = input_.view(-1, 512*7*7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二段模块输出收集，这个是全连接模块,输入shape=[batch_size,C * H * W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.609244Z",
     "start_time": "2020-05-13T06:01:06.553277Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(35, len(mods)):\n",
    "    m = mods[i]\n",
    "    if isinstance(m, nn.ReLU):\n",
    "        # inplace=True means that it will modify the input directly, without allocating any additional\n",
    "        # output. It can sometimes slightly decrease the memory usage, but may not always be a valid\n",
    "        # operation(because the original input is destroyed). if you don't see an error, it means that\n",
    "        # your use case is valid\n",
    "        if m.inplace:\n",
    "            continue\n",
    "    out = m(input_)\n",
    "    out_sizes.append(np.array(out.size()))\n",
    "    input_ = out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 展示收集到的中间变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.613520Z",
     "start_time": "2020-05-13T06:01:06.610056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  1,  64, 224, 224]),\n",
       " array([  1,  64, 224, 224]),\n",
       " array([  1,  64, 112, 112]),\n",
       " array([  1, 128, 112, 112]),\n",
       " array([  1, 128, 112, 112]),\n",
       " array([  1, 128,  56,  56]),\n",
       " array([  1, 256,  56,  56]),\n",
       " array([  1, 256,  56,  56]),\n",
       " array([  1, 256,  56,  56]),\n",
       " array([  1, 256,  28,  28]),\n",
       " array([  1, 512,  28,  28]),\n",
       " array([  1, 512,  28,  28]),\n",
       " array([  1, 512,  28,  28]),\n",
       " array([  1, 512,  14,  14]),\n",
       " array([  1, 512,  14,  14]),\n",
       " array([  1, 512,  14,  14]),\n",
       " array([  1, 512,  14,  14]),\n",
       " array([  1, 512,   7,   7]),\n",
       " array([  1, 512,   7,   7]),\n",
       " array([   1, 4096]),\n",
       " array([   1, 4096]),\n",
       " array([   1, 4096]),\n",
       " array([   1, 4096]),\n",
       " array([   1, 1000])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计中间输出变量的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.617807Z",
     "start_time": "2020-05-13T06:01:06.614294Z"
    }
   },
   "outputs": [],
   "source": [
    "total_nums = 0\n",
    "for i in range(len(out_sizes)):\n",
    "    s = out_sizes[i]\n",
    "    nums = np.prod(np.array(s))\n",
    "    total_nums += nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.624237Z",
     "start_time": "2020-05-13T06:01:06.618529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15120360"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转化成熟悉的Mb表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T06:01:06.631323Z",
     "start_time": "2020-05-13T06:01:06.625096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model VGG : intermedite variables: 60.481 M (without backward)\n",
      "Model VGG : intermedite variables: 120.963 M (with backward)\n"
     ]
    }
   ],
   "source": [
    "print(\"Model {} : intermedite variables: {:.3f} M (without backward)\".format(model._get_name(), total_nums * 4 / 1000 /1000))\n",
    "print(\"Model {} : intermedite variables: {:.3f} M (with backward)\".format(model._get_name(), total_nums * 2 * 4 / 1000 / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
