{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[文章参考来源](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#serializing-a-pruned-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = LeNet().to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 监测conv1，其中包含了weight和bias,因为还没使用conv1，所以没有buffers产生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = model.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先说一下后面会用到的几个概念，\n",
    "model.conv1.weight   这里的weight是属性,运行prune操作之后产生的稀疏权重会存储在这里，然后我们需要运行prune.remove()操作，才能让model.conv1.weight和model.conv1.named_parameters()的显示结果变成一样\n",
    "\n",
    "model.conv1.named_buffers()  运行prune操作后，生成的mask会在这里\n",
    "\n",
    "model.conv1.named_parameters()   模型参数的存储位置,这里面的值会跟随torch.save()存储到本地的.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[-0.2455,  0.0065, -0.1007],\n",
       "            [-0.2746,  0.1460, -0.1434],\n",
       "            [ 0.0533, -0.1866, -0.2310]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2056, -0.0561, -0.1685],\n",
       "            [ 0.1527, -0.1482,  0.2526],\n",
       "            [ 0.0145, -0.0996,  0.2773]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2489, -0.1215,  0.1214],\n",
       "            [ 0.1938, -0.2379,  0.2340],\n",
       "            [-0.2849,  0.2429,  0.1251]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2392, -0.1834,  0.1596],\n",
       "            [-0.1394,  0.2261, -0.2334],\n",
       "            [-0.2830, -0.1771, -0.1306]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0442,  0.2732,  0.3017],\n",
       "            [-0.0153,  0.3309,  0.0380],\n",
       "            [ 0.0040,  0.2164, -0.1804]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.2539,  0.0888, -0.0319],\n",
       "            [ 0.1115, -0.1317, -0.1421],\n",
       "            [ 0.1865, -0.3027,  0.0986]]]], device='cuda:0', requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.2467,  0.2349, -0.2630, -0.0814,  0.1895,  0.2932], device='cuda:0',\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.2455,  0.0065, -0.1007],\n",
       "          [-0.2746,  0.1460, -0.1434],\n",
       "          [ 0.0533, -0.1866, -0.2310]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2056, -0.0561, -0.1685],\n",
       "          [ 0.1527, -0.1482,  0.2526],\n",
       "          [ 0.0145, -0.0996,  0.2773]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2489, -0.1215,  0.1214],\n",
       "          [ 0.1938, -0.2379,  0.2340],\n",
       "          [-0.2849,  0.2429,  0.1251]]],\n",
       "\n",
       "\n",
       "        [[[-0.2392, -0.1834,  0.1596],\n",
       "          [-0.1394,  0.2261, -0.2334],\n",
       "          [-0.2830, -0.1771, -0.1306]]],\n",
       "\n",
       "\n",
       "        [[[-0.0442,  0.2732,  0.3017],\n",
       "          [-0.0153,  0.3309,  0.0380],\n",
       "          [ 0.0040,  0.2164, -0.1804]]],\n",
       "\n",
       "\n",
       "        [[[-0.2539,  0.0888, -0.0319],\n",
       "          [ 0.1115, -0.1317, -0.1421],\n",
       "          [ 0.1865, -0.3027,  0.0986]]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为还没使用过conv1,所以这里的buffers为空，调用prune之后你会发现差别的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(module.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用prune对conv1里的weight进行剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.random_unstructured(module, name=\"weight\", amount=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以发现这里的weight被重命名为weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([-0.2467,  0.2349, -0.2630, -0.0814,  0.1895,  0.2932], device='cuda:0',\n",
      "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[[[-0.2455,  0.0065, -0.1007],\n",
      "          [-0.2746,  0.1460, -0.1434],\n",
      "          [ 0.0533, -0.1866, -0.2310]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2056, -0.0561, -0.1685],\n",
      "          [ 0.1527, -0.1482,  0.2526],\n",
      "          [ 0.0145, -0.0996,  0.2773]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2489, -0.1215,  0.1214],\n",
      "          [ 0.1938, -0.2379,  0.2340],\n",
      "          [-0.2849,  0.2429,  0.1251]]],\n",
      "\n",
      "\n",
      "        [[[-0.2392, -0.1834,  0.1596],\n",
      "          [-0.1394,  0.2261, -0.2334],\n",
      "          [-0.2830, -0.1771, -0.1306]]],\n",
      "\n",
      "\n",
      "        [[[-0.0442,  0.2732,  0.3017],\n",
      "          [-0.0153,  0.3309,  0.0380],\n",
      "          [ 0.0040,  0.2164, -0.1804]]],\n",
      "\n",
      "\n",
      "        [[[-0.2539,  0.0888, -0.0319],\n",
      "          [ 0.1115, -0.1317, -0.1421],\n",
      "          [ 0.1865, -0.3027,  0.0986]]]], device='cuda:0', requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.conv1.weight 这里的weight是属性,运行prune操作之后产生的稀疏权重会存储在这里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2455,  0.0065, -0.1007],\n",
       "          [-0.2746,  0.1460, -0.1434],\n",
       "          [ 0.0533, -0.1866, -0.2310]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2056, -0.0561, -0.0000],\n",
       "          [ 0.1527, -0.0000,  0.2526],\n",
       "          [ 0.0145, -0.0000,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2489, -0.1215,  0.1214],\n",
       "          [ 0.0000, -0.0000,  0.2340],\n",
       "          [-0.2849,  0.2429,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.2392, -0.1834,  0.1596],\n",
       "          [-0.0000,  0.2261, -0.2334],\n",
       "          [-0.0000, -0.1771, -0.1306]]],\n",
       "\n",
       "\n",
       "        [[[-0.0442,  0.0000,  0.3017],\n",
       "          [-0.0153,  0.3309,  0.0380],\n",
       "          [ 0.0040,  0.0000, -0.1804]]],\n",
       "\n",
       "\n",
       "        [[[-0.2539,  0.0000, -0.0000],\n",
       "          [ 0.0000, -0.0000, -0.0000],\n",
       "          [ 0.1865, -0.3027,  0.0986]]]], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.conv1.named_buffers() 运行prune操作后，生成的mask会在这里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.],\n",
      "          [1., 0., 1.],\n",
      "          [1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [0., 0., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [0., 1., 1.],\n",
      "          [0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [1., 1., 1.]]]], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(0, <torch.nn.utils.prune.RandomUnstructured object at 0x7f110f8550b8>)])\n"
     ]
    }
   ],
   "source": [
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行L1的Pruning操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(module, name='bias', amount=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_orig', Parameter containing:\n",
      "tensor([[[[-0.2455,  0.0065, -0.1007],\n",
      "          [-0.2746,  0.1460, -0.1434],\n",
      "          [ 0.0533, -0.1866, -0.2310]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2056, -0.0561, -0.1685],\n",
      "          [ 0.1527, -0.1482,  0.2526],\n",
      "          [ 0.0145, -0.0996,  0.2773]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2489, -0.1215,  0.1214],\n",
      "          [ 0.1938, -0.2379,  0.2340],\n",
      "          [-0.2849,  0.2429,  0.1251]]],\n",
      "\n",
      "\n",
      "        [[[-0.2392, -0.1834,  0.1596],\n",
      "          [-0.1394,  0.2261, -0.2334],\n",
      "          [-0.2830, -0.1771, -0.1306]]],\n",
      "\n",
      "\n",
      "        [[[-0.0442,  0.2732,  0.3017],\n",
      "          [-0.0153,  0.3309,  0.0380],\n",
      "          [ 0.0040,  0.2164, -0.1804]]],\n",
      "\n",
      "\n",
      "        [[[-0.2539,  0.0888, -0.0319],\n",
      "          [ 0.1115, -0.1317, -0.1421],\n",
      "          [ 0.1865, -0.3027,  0.0986]]]], device='cuda:0', requires_grad=True)), ('bias_orig', Parameter containing:\n",
      "tensor([-0.2467,  0.2349, -0.2630, -0.0814,  0.1895,  0.2932], device='cuda:0',\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.],\n",
      "          [1., 0., 1.],\n",
      "          [1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [0., 0., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [0., 1., 1.],\n",
      "          [0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [1., 1., 1.]]]], device='cuda:0')), ('bias_mask', tensor([1., 0., 1., 0., 0., 1.], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2467,  0.0000, -0.2630, -0.0000,  0.0000,  0.2932], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(0, <torch.nn.utils.prune.RandomUnstructured object at 0x7f110f8550b8>), (1, <torch.nn.utils.prune.L1Unstructured object at 0x7f110f86d860>)])\n"
     ]
    }
   ],
   "source": [
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这里进行了structured pruning，注意看输出的weight,都是一整个channel为0的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.ln_structured(module, name='weight', amount=0.5, n=2, dim=0)\n",
    "# as we can verify, this will zero out all the connections corresponding to 50%(3 out of 6) of the channels,\n",
    "# while preserving the action of the previous mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the forward pass to work without modification, the weight attribute needs to exist. The pruning techniques implemented in torch.nn.utils.prune compute the pruned version of the weight (by combining the mask with the original parameter) and store them in the attribute weight. Note, this is no longer a parameter of the module, it is now simply an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2455,  0.0065, -0.1007],\n",
      "          [-0.2746,  0.1460, -0.1434],\n",
      "          [ 0.0533, -0.1866, -0.2310]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2489, -0.1215,  0.1214],\n",
      "          [ 0.0000, -0.0000,  0.2340],\n",
      "          [-0.2849,  0.2429,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.2392, -0.1834,  0.1596],\n",
      "          [-0.0000,  0.2261, -0.2334],\n",
      "          [-0.0000, -0.1771, -0.1306]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<torch.nn.utils.prune.RandomUnstructured object at 0x7f110f8550b8>, <torch.nn.utils.prune.LnStructured object at 0x7f1106a14a90>]\n"
     ]
    }
   ],
   "source": [
    "for hook in module._forward_pre_hooks.values():\n",
    "    if hook._tensor_name == 'weight':\n",
    "        break\n",
    "\n",
    "print(list(hook))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可以看到存在weight_orig和weight_mask，两者运算之后产生prune之后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_orig', Parameter containing:\n",
      "tensor([[[[-0.2455,  0.0065, -0.1007],\n",
      "          [-0.2746,  0.1460, -0.1434],\n",
      "          [ 0.0533, -0.1866, -0.2310]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2056, -0.0561, -0.1685],\n",
      "          [ 0.1527, -0.1482,  0.2526],\n",
      "          [ 0.0145, -0.0996,  0.2773]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2489, -0.1215,  0.1214],\n",
      "          [ 0.1938, -0.2379,  0.2340],\n",
      "          [-0.2849,  0.2429,  0.1251]]],\n",
      "\n",
      "\n",
      "        [[[-0.2392, -0.1834,  0.1596],\n",
      "          [-0.1394,  0.2261, -0.2334],\n",
      "          [-0.2830, -0.1771, -0.1306]]],\n",
      "\n",
      "\n",
      "        [[[-0.0442,  0.2732,  0.3017],\n",
      "          [-0.0153,  0.3309,  0.0380],\n",
      "          [ 0.0040,  0.2164, -0.1804]]],\n",
      "\n",
      "\n",
      "        [[[-0.2539,  0.0888, -0.0319],\n",
      "          [ 0.1115, -0.1317, -0.1421],\n",
      "          [ 0.1865, -0.3027,  0.0986]]]], device='cuda:0', requires_grad=True)), ('bias_orig', Parameter containing:\n",
      "tensor([-0.2467,  0.2349, -0.2630, -0.0814,  0.1895,  0.2932], device='cuda:0',\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight_mask', tensor([[[[1., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [0., 0., 1.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.],\n",
      "          [0., 1., 1.],\n",
      "          [0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.],\n",
      "          [0., 0., 0.],\n",
      "          [0., 0., 0.]]]], device='cuda:0')), ('bias_mask', tensor([1., 0., 1., 0., 0., 1.], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2455,  0.0065, -0.1007],\n",
      "          [-0.2746,  0.1460, -0.1434],\n",
      "          [ 0.0533, -0.1866, -0.2310]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2489, -0.1215,  0.1214],\n",
      "          [ 0.0000, -0.0000,  0.2340],\n",
      "          [-0.2849,  0.2429,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.2392, -0.1834,  0.1596],\n",
      "          [-0.0000,  0.2261, -0.2334],\n",
      "          [-0.0000, -0.1771, -0.1306]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(module.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行prune.remove的作用，To make the pruning permanent, remove the re-parametrization in terms of weight_orig and weight_mask, and remove the forward_pre_hook, we can use the remove functionality from torch.nn.utils.prune. Note that this doesn't undo the pruning, as if it never happened. It simply makes it permanent, instead, by reassigning the parameter weight to the model parameters, in its pruned version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prune.remove之后，我们发现weight_orig变成了weight,其实就是把module.weight的值赋值给了weight_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias_orig', Parameter containing:\n",
      "tensor([-0.2467,  0.2349, -0.2630, -0.0814,  0.1895,  0.2932], device='cuda:0',\n",
      "       requires_grad=True)), ('weight', Parameter containing:\n",
      "tensor([[[[-0.2455,  0.0065, -0.1007],\n",
      "          [-0.2746,  0.1460, -0.1434],\n",
      "          [ 0.0533, -0.1866, -0.2310]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2489, -0.1215,  0.1214],\n",
      "          [ 0.0000, -0.0000,  0.2340],\n",
      "          [-0.2849,  0.2429,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.2392, -0.1834,  0.1596],\n",
      "          [-0.0000,  0.2261, -0.2334],\n",
      "          [-0.0000, -0.1771, -0.1306]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]]]], device='cuda:0', requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "prune.remove(module, 'weight')\n",
    "print(list(module.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias_mask', tensor([1., 0., 1., 0., 0., 1.], device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "print(list(module.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prunning multiple parameters in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = LeNet()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in new_model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.2)\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask'])\n"
     ]
    }
   ],
   "source": [
    "print(dict(new_model.named_buffers()).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Prunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we only looked at what is usually referred to as \"local\" pruning, i.e. the practice of pruning tensors in a model one by one, by comparing the statistics (weight magnitude, activation, gradient, etc.) of each entry exclusively to the other entries in that tensor. However, a common and perhaps more powerful technique is to prune the model all at once, by removing (for example) the lowest 20% of connections across the whole model, instead of removing the lowest 20% of connections in each layer. This is likely to result in different pruning percentages per layer. Let's see how to do that using global_unstructured from torch.nn.utils.prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "\n",
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    "    (model.fc3, 'weight')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount = 0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv1.weight: 11.11%\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparsity in conv1.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.conv1.weight == 0)) / \n",
    "     float(model.conv1.weight.nelement())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in conv2.weight: 27.31%\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparsity in conv2.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.conv2.weight == 0)) /\n",
    "                                                float(model.conv2.weight.nelement())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in fc1.weight: 77.34%\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparsity in fc1.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc1.weight == 0)) / \n",
    "     float(model.fc1.weight.nelement())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in fc2.weight: 41.76%\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparsity in fc2.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc2.weight == 0)) / \n",
    "     float(model.fc2.weight.nelement())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in fc3.weight: 37.50%\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparsity in fc3.weight: {:.2f}%\".format(100.0 * float(torch.sum(model.fc3.weight == 0)) /\n",
    "                                              float(model.fc3.weight.nelement())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity: 70.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Global sparsity: {:.2f}%\".format(\n",
    "    100.0 * float(\n",
    "        torch.sum(model.conv1.weight == 0)\n",
    "        + torch.sum(model.conv2.weight == 0)\n",
    "        + torch.sum(model.fc1.weight == 0)\n",
    "        + torch.sum(model.fc2.weight == 0)\n",
    "        + torch.sum(model.fc3.weight == 0)\n",
    "    )\n",
    "    / float(\n",
    "        model.conv1.weight.nelement()\n",
    "        + model.conv2.weight.nelement()\n",
    "        + model.fc1.weight.nelement()\n",
    "        + model.fc2.weight.nelement()\n",
    "        + model.fc3.weight.nelement()\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算0值的个数，结果看来是吻合的，计算结果为14.81%稀疏度，在conv1层的weight上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(model.conv1.weight == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.814814814814813"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8 / 54.0 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000, -0.2941, -0.0869],\n",
       "          [ 0.2473, -0.1696, -0.0801],\n",
       "          [-0.1297, -0.3271,  0.2942]]],\n",
       "\n",
       "\n",
       "        [[[-0.3062, -0.2663, -0.2162],\n",
       "          [ 0.0476, -0.2757,  0.2436],\n",
       "          [-0.2258,  0.0679, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2015,  0.0000,  0.2316],\n",
       "          [ 0.2343, -0.2772,  0.3242],\n",
       "          [-0.1783, -0.0607, -0.2033]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0815, -0.2245,  0.3070],\n",
       "          [-0.0744, -0.1191,  0.1764],\n",
       "          [ 0.3127,  0.2398,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3139,  0.0565, -0.2029],\n",
       "          [ 0.3229, -0.2615, -0.2801],\n",
       "          [-0.0000, -0.2270, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.1660,  0.1511,  0.1712],\n",
       "          [ 0.2690, -0.0737, -0.2197],\n",
       "          [ 0.2962,  0.1628, -0.0903]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.2342, -0.2550, -0.1118,  0.2898, -0.0040,  0.0299],\n",
       "         requires_grad=True)),\n",
       " ('weight_orig',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0311, -0.2941, -0.0869],\n",
       "            [ 0.2473, -0.1696, -0.0801],\n",
       "            [-0.1297, -0.3271,  0.2942]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3062, -0.2663, -0.2162],\n",
       "            [ 0.0476, -0.2757,  0.2436],\n",
       "            [-0.2258,  0.0679, -0.0202]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2015,  0.0066,  0.2316],\n",
       "            [ 0.2343, -0.2772,  0.3242],\n",
       "            [-0.1783, -0.0607, -0.2033]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0815, -0.2245,  0.3070],\n",
       "            [-0.0744, -0.1191,  0.1764],\n",
       "            [ 0.3127,  0.2398,  0.0317]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3139,  0.0565, -0.2029],\n",
       "            [ 0.3229, -0.2615, -0.2801],\n",
       "            [-0.0097, -0.2270, -0.0180]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1660,  0.1511,  0.1712],\n",
       "            [ 0.2690, -0.0737, -0.2197],\n",
       "            [ 0.2962,  0.1628, -0.0903]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在保存模型之前，对每个layer运行prune.remove操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1)) weight\n",
      "Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1)) weight\n",
      "Linear(in_features=400, out_features=120, bias=True) weight\n",
      "Linear(in_features=120, out_features=84, bias=True) weight\n",
      "Linear(in_features=84, out_features=10, bias=True) weight\n"
     ]
    }
   ],
   "source": [
    "for module, name in parameters_to_prune:\n",
    "    print(module, name)\n",
    "    prune.remove(module, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.2342, -0.2550, -0.1118,  0.2898, -0.0040,  0.0299],\n",
       "         requires_grad=True)),\n",
       " ('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[[[ 0.0000, -0.2941, -0.0869],\n",
       "            [ 0.2473, -0.1696, -0.0801],\n",
       "            [-0.1297, -0.3271,  0.2942]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.3062, -0.2663, -0.2162],\n",
       "            [ 0.0476, -0.2757,  0.2436],\n",
       "            [-0.2258,  0.0679, -0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.2015,  0.0000,  0.2316],\n",
       "            [ 0.2343, -0.2772,  0.3242],\n",
       "            [-0.1783, -0.0607, -0.2033]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.0815, -0.2245,  0.3070],\n",
       "            [-0.0744, -0.1191,  0.1764],\n",
       "            [ 0.3127,  0.2398,  0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[ 0.3139,  0.0565, -0.2029],\n",
       "            [ 0.3229, -0.2615, -0.2801],\n",
       "            [-0.0000, -0.2270, -0.0000]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1660,  0.1511,  0.1712],\n",
       "            [ 0.2690, -0.0737, -0.2197],\n",
       "            [ 0.2962,  0.1628, -0.0903]]]], requires_grad=True))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.named_buffers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型以及比较.pth个压缩后的.zip格式模型的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'sparse_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6232423490488007"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(241.8 - 91.1) / 241.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0000, -0.2941, -0.0869],\n",
       "          [ 0.2473, -0.1696, -0.0801],\n",
       "          [-0.1297, -0.3271,  0.2942]]],\n",
       "\n",
       "\n",
       "        [[[-0.3062, -0.2663, -0.2162],\n",
       "          [ 0.0476, -0.2757,  0.2436],\n",
       "          [-0.2258,  0.0679, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2015,  0.0000,  0.2316],\n",
       "          [ 0.2343, -0.2772,  0.3242],\n",
       "          [-0.1783, -0.0607, -0.2033]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0815, -0.2245,  0.3070],\n",
       "          [-0.0744, -0.1191,  0.1764],\n",
       "          [ 0.3127,  0.2398,  0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3139,  0.0565, -0.2029],\n",
       "          [ 0.3229, -0.2615, -0.2801],\n",
       "          [-0.0000, -0.2270, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.1660,  0.1511,  0.1712],\n",
       "          [ 0.2690, -0.0737, -0.2197],\n",
       "          [ 0.2962,  0.1628, -0.0903]]]], requires_grad=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
