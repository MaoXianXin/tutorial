# Tensorflow2.0

![Selection_011](pics/Selection_011.jpg)

## Tesla服务器显卡(V100双卡)

![Selection_010](pics/Selection_010.jpg)

![Selection_009](pics/Selection_009.jpg)

![Selection_008](pics/Selection_008.jpg)

我们发现，随着训练的进行，每个epoch所花费的时间大概是在103s，显卡的利用率基本维持在95%以上，显卡的显存也是打满的，显卡的温度维持在60度左右，此处还把内存加载成硬盘使用

**sudo mount tmpfs /path/to/your/data -t tmpfs -o size=30G**

## RTX消费级显卡(RTX2080Ti双卡)

![Selection_012](pics/Selection_012.jpg)

![Selection_007](pics/Selection_007.jpg)

![Selection_013](pics/Selection_013.jpg)

我们发现，随着训练的进行，每个epoch所花费的时间，一开始是175s，之后是189s，然后是196s，最后大致稳定在199s，显卡的利用率基本维持在95%以上，显卡的显存也是打满的，显卡温度维持在80度左右

对比V100和RTX2080Ti的每个epoch训练时间，我们可以发现云服务还是有优势的，主要体现在稳定性，比如降温处理等，而且对于长时间训练来说，服务器显卡表现的更加稳定